[{"content":"Introduction Window Functions were introduced in ANSI SQL:2003, making them a relatively new feature. They allow functions to be applied to a set of rows using the OVER clause.\nOne of the most common use cases for window functions is analytical queries, specifically identifying islands and gaps in a dataset.\nIslands are groups of continuous data sequences. Gaps are missing sequences between data points. Dataset Here\u0026rsquo;s the initial dataset:\ncol1 2 3 11 12 13 27 33 34 35 42 Creating the Dataset 1 2 3 4 5 6 7 8 9 10 11 12 DROP TABLE IF EXISTS table1; CREATE TEMPORARY TABLE table1( col1 INT NOT NULL GENERATED BY DEFAULT AS IDENTITY ); INSERT INTO table1(col1) VALUES (2), (3), (11), (12), (13), (27), (33), (34), (35), (42); SELECT col1 FROM table1 ORDER BY col1; Expected Output After identifying islands in the dataset, we should get the following result:\nstart_range end_range 2 3 11 13 27 27 33 35 42 42 Algorithmic Approach To solve this, we need to group numbers that belong to the same continuous sequence (island).\ncol1 grp 2 a 3 a 11 b 12 b 13 b 27 c 33 d 34 d 35 d 42 e Each group (grp) represents an island, where numbers belong to a continuous sequence. For example, group D represents the sequence 33, 34, 35.\nSQL Implementation We can use window functions to achieve this:\n1 2 3 4 SELECT col1, col1 - ROW_NUMBER() OVER(ORDER BY col1) AS grp FROM table1; Output col1 grp 2 1 3 1 11 8 12 8 13 8 27 21 33 26 34 26 35 26 42 32 Explanation By subtracting ROW_NUMBER() OVER(ORDER BY col1) from col1, we create a unique identifier (grp) for each island. Numbers in the same sequence get the same grp value. Final Query Now, we just need to group by the grp column to get the start and end of each island:\n1 2 3 4 5 6 7 8 9 10 11 12 WITH grp AS ( SELECT col1, col1 - ROW_NUMBER() OVER(ORDER BY col1) AS grp FROM table1 ) SELECT MIN(col1) AS start_range, MAX(col1) AS end_range FROM grp GROUP BY grp ORDER BY start_range; Final Output start_range end_range 2 3 11 13 27 27 33 35 42 42 Conclusion By leveraging window functions, we efficiently identify islands in a dataset using row numbering and grouping techniques. This method can be extended to various real-world use cases, such as:\nTracking continuous patient visits in healthcare analytics. Identifying consecutive login days in user behavior analysis. Detecting gaps in financial transactions for fraud detection. Credits Pictures Easter island References SQL Example were taken from \u0026ldquo;T-SQL Window Functions, Second Edition For data analysis and beyond\u0026rdquo; by Itzik Ben-Gan ","date":"2025-03-02T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/using-window-functions-to-find-island/easter-island-3733247_1280_huffd17f660520c0e39396e0e2c513b69e_93862_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/using-window-functions-to-find-island/","title":"Using Window Functions to find Islands"},{"content":"Introduction This article outlines how I structure my R Shiny codebase. Whenever I start a new Shiny application, I use the following structure:\n1 2 3 4 5 modules/ utils/ ui.R server.R global.R Separation of UI Logic and Server Logic In Mastering Shiny by Hadley Wickham, the ui and server logic are combined in app.R. However, I prefer to separate them into ui.R and server.R for better organization.\nTemplate for server.R 1 2 3 4 5 6 7 library(shiny) library(bs4Dash) # Define server logic server \u0026lt;- function(input, output) { set.seed(122) } I always set a seed for reproducibility, ensuring consistency in functions that involve pseudo-randomness (e.g., random sampling).\nExample of ui.R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 library(shiny) library(bs4Dash) library(fresh) # Sidebar ----------------------------------------------------------------- sidebar \u0026lt;- dashboardSidebar( sidebarMenu( menuItem(\u0026#34;Home\u0026#34;, tabName = \u0026#34;home\u0026#34;, icon = icon(\u0026#34;home\u0026#34;)) ) ) # Body -------------------------------------------------------------------- body \u0026lt;- dashboardBody( fresh::use_theme(theme), # theme is defined in global.R tabItems( tabItem( tabName = \u0026#34;home\u0026#34;, fluidRow( ) ) ) ) # Header ------------------------------------------------------------------ header \u0026lt;- dashboardHeader(title = \u0026#34;TOMIC\u0026#34;) # Dashboard Page ---------------------------------------------------------- # Define UI for application ui \u0026lt;- dashboardPage( freshTheme = theme, header, sidebar, body ) This setup leverages the fresh package for theming alongside bs4Dash.\nGlobal Functions and Variables The global.R file is automatically recognized by Shiny. It stores global variables and functions used throughout the application. For specific functions, I place them in the utils/ directory.\nTemplate for global.R 1 2 3 4 5 6 7 8 9 10 11 library(fresh) # Source ------------------------------------------------------------------ ## utils util_file_names \u0026lt;- list.files(path = \u0026#34;utils/\u0026#34;, pattern = \u0026#34;\\\\.R$\u0026#34;, full.names = TRUE) lapply(util_file_names, source) ## modules mods_file_names \u0026lt;- list.files(path = \u0026#34;modules/\u0026#34;, pattern = \u0026#34;\\\\.R$\u0026#34;, full.names = TRUE) lapply(mods_file_names, source) This ensures all modules and utility functions are automatically loaded.\nExample of global.R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 library(fresh) # Source ------------------------------------------------------------------ ## utils util_file_names \u0026lt;- list.files(path = \u0026#34;utils/\u0026#34;, pattern = \u0026#34;\\\\.R$\u0026#34;, full.names = TRUE) lapply(util_file_names, source) ## modules mods_file_names \u0026lt;- list.files(path = \u0026#34;modules/\u0026#34;, pattern = \u0026#34;\\\\.R$\u0026#34;, full.names = TRUE) lapply(mods_file_names, source) # Theme ------------------------------------------------------------------- # Create the theme theme \u0026lt;- fresh::create_theme( bs4dash_color( # green = \u0026#34;#3fff2d\u0026#34;, # blue = \u0026#34;#2635ff\u0026#34;, # red = \u0026#34;\t#ff2b2b\u0026#34;, # yellow = \u0026#34;#feff6e\u0026#34;, # fuchsia = \u0026#34;#ff5bf8\u0026#34;, # navy = \u0026#34;#374c92\u0026#34;, # purple = \u0026#34;#615cbf\u0026#34;, # maroon = \u0026#34;#b659c9\u0026#34;, # lightblue = \u0026#34;#5691cc\u0026#34; lightblue = \u0026#34;#434C5E\u0026#34; ), bs4dash_sidebar_light( bg = \u0026#34;#D8DEE9\u0026#34;, hover_bg = \u0026#34;#81A1C1\u0026#34;, color = \u0026#34;#2E3440\u0026#34; ), bs4dash_sidebar_dark( bg = \u0026#34;#2E3440\u0026#34;, hover_bg = \u0026#34;#81A1C1\u0026#34;, color = \u0026#34;#D8DEE9\u0026#34; ), bs4dash_vars( content_bg = \u0026#34;#FFF\u0026#34;, box_bg = \u0026#34;#D8DEE9\u0026#34;, info_box_bg = \u0026#34;#D8DEE9\u0026#34; ) ) # Global Variables -------------------------------------------------------- watchlist \u0026lt;- c(\u0026#34;MARA\u0026#34;, \u0026#34;NVDA\u0026#34;, \u0026#34;CELH\u0026#34;, \u0026#34;BITX\u0026#34;, \u0026#34;PL\u0026#34;) markets \u0026lt;- c(\u0026#34;^NDX\u0026#34;, \u0026#34;^GSPC\u0026#34;, \u0026#34;^DJI\u0026#34;, \u0026#34;^TNX\u0026#34;) # Nasdaq100 and SP500 # Functions ---- get_yearly_data \u0026lt;- function(ticker) { data \u0026lt;- tq_get(ticker, get = \u0026#34;stock.prices\u0026#34;, complete_cases = TRUE) data %\u0026gt;% filter(date \u0026gt;= today() - months(12)) } get_weekly_data \u0026lt;- function(ticker) { data \u0026lt;- tq_get(ticker, get = \u0026#34;stock.prices\u0026#34;, complete_cases = TRUE) data %\u0026gt;% filter(date \u0026gt;= today() - weeks(1)) } plot_index_graph \u0026lt;- function(data) { ggplotly({ data %\u0026gt;% ggplot(aes(date, close)) + geom_line(size = 0.4, alpha = .9) + xlab(\u0026#34;Time\u0026#34;) + ylab(\u0026#34;Points\u0026#34;) + theme_minimal() }) } The theme variable is referenced in ui.R to apply consistent styling.\nUtilities (utils/) Example: utils/ticker_utils.R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 symbol_daily_performance \u0026lt;- function(ticker, sym_name, sym_emoji = \u0026#34;\u0026#34;, value_font_size = \u0026#34;150%\u0026#34;) { value_font_size \u0026lt;- paste(\u0026#34;font-size: \u0026#34;, value_font_size, \u0026#34;;\u0026#34;, sep = \u0026#34;\u0026#34;) sym \u0026lt;- tq_get( ticker, from = lubridate::today() - 7, to = lubridate::today() + lubridate::days(1) ) %\u0026gt;% group_by(symbol) %\u0026gt;% slice_tail(n = 2) %\u0026gt;% mutate( symbol_move = round(close - lag(close, 1), digits = 2), symbol_move_return = round( (close - lag(close, 1)) / lag(close, 1) * 100, digits = 2 ) ) %\u0026gt;% drop_na(symbol_move) %\u0026gt;% select(symbol, date, symbol_move, symbol_move_return) sym_subtitle \u0026lt;- paste(\u0026#34;+\u0026#34;, sym$symbol_move, \u0026#34; (+\u0026#34;, sym$symbol_move_return, \u0026#34;%)\u0026#34;, sep = \u0026#34;\u0026#34;) sym_color \u0026lt;- \u0026#34;gray\u0026#34; sym_icon \u0026lt;- \u0026#34;ellipsis-horizontal\u0026#34; sym_value \u0026lt;- \u0026#34;\u0026#34; if (sym$symbol_move_return \u0026gt; 0) { sym_color \u0026lt;- \u0026#34;success\u0026#34; sym_icon \u0026lt;- \u0026#34;trending-up\u0026#34; } else if (sym$symbol_move_return \u0026lt; 0) { sym_color \u0026lt;- \u0026#34;danger\u0026#34; sym_icon \u0026lt;- \u0026#34;trending-down\u0026#34; } bs4ValueBox( value = tags$p( paste(sym_name, \u0026#34; \u0026#34;, sym_value, \u0026#34; \u0026#34;, sym_emoji), style = value_font_size ), subtitle = sym_subtitle, color = sym_color, icon = ionicon(sym_icon) ) } Modules (modules/) Shiny modules allow for better reusability and maintainability.\nExample: modules\\watchlist_mod.R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 watchlistUI \u0026lt;- function(id) { ns \u0026lt;- NS(id) tagList( box( title = uiOutput(ns(\u0026#34;watchlist_placeholder\u0026#34;)), id = ns(\u0026#34;watchlist\u0026#34;), DT::DTOutput(ns(\u0026#34;watchlist\u0026#34;)) ) ) } watchlistServer \u0026lt;- function(id, watchlist) { moduleServer( id, function(input, output, session) { # watch list watchlist_data \u0026lt;- tq_get( watchlist, from = lubridate::today() - 7, to = lubridate::today() + lubridate::days(1) ) %\u0026gt;% group_by(symbol) %\u0026gt;% slice_tail(n = 2) %\u0026gt;% mutate( symbol_move = round(close - lag(close, 1), digits = 2), symbol_move_return = round( (close - lag(close, 1)) / lag(close, 1) * 100, digits = 2 ), close = round(close, digits = 2) ) %\u0026gt;% drop_na(symbol_move) %\u0026gt;% select(symbol, date, symbol_move, symbol_move_return, close) output$watchlist_placeholder \u0026lt;- renderUI({ title \u0026lt;- paste(\u0026#34;Watchlist \u0026#34;, watchlist_data$date[1]) }) watchlist_data2 \u0026lt;- watchlist_data %\u0026gt;% select(symbol, symbol_move, symbol_move_return, close) watchlist_dt \u0026lt;- datatable( watchlist_data2, options = list( rowCallback = JS(\u0026#39; function(nRow, aData) { if (Number(aData[3]) \u0026lt; 0) { $(nRow).css(\u0026#34;background-color\u0026#34;, \u0026#34;#ff99bb\u0026#34;) } else if (Number(aData[3]) \u0026gt; 1) { $(nRow).css(\u0026#34;background-color\u0026#34;, \u0026#34;#d9e8a7\u0026#34;) } }\u0026#39;) ), colnames = c(\u0026#34;sym\u0026#34;, \u0026#34;$\u0026#34;, \u0026#34;%\u0026#34;, \u0026#34;close\u0026#34;) ) output$watchlist \u0026lt;- DT::renderDataTable( watchlist_dt ) } ) } Another example: modules\\vix_value_box_mod.R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 library(shiny) vixValueBoxUI \u0026lt;- function(id) { ns \u0026lt;- NS(id) tagList( valueBoxOutput(ns(\u0026#34;vix_score\u0026#34;)) ) } vixValueBoxServer \u0026lt;- function(id) { moduleServer(id, function(input, output, session) { vix \u0026lt;- reactive( tq_get( \u0026#34;^VIX\u0026#34;, from = lubridate::today() - 7, to = lubridate::today() + lubridate::days(1) ) %\u0026gt;% slice_tail(n = 1) %\u0026gt;% mutate( symbol = \u0026#34;VIX\u0026#34;, close = round(close, digits = 2) ) %\u0026gt;% select(close) ) vix_subtitle \u0026lt;- \u0026#34;VIX\u0026#34; output$vix_score \u0026lt;- renderbs4ValueBox({ # 0-15: This can indicate a certain amount of optimism in the market as well as very low volatility. if (vix() \u0026gt;= 0 \u0026amp; vix() \u0026lt;= 15) { vix_subtitle \u0026lt;- paste0(\u0026#34;VIX: \u0026#34;, vix(), \u0026#34; certain amount of optimism and very low volatility 🐮\u0026#34;) vix_subtitle2 \u0026lt;- paste0(\u0026#34;Certain amount of optimism and very low volatility 🐮\u0026#34;) color \u0026lt;- \u0026#34;success\u0026#34; icon \u0026lt;- \u0026#34;happy\u0026#34; # 15-25: This can indicate that there is a certain amount of volatility, but nothing extreme. } else if (vix() \u0026gt; 15 \u0026amp; vix() \u0026lt;= 25) { vix_subtitle \u0026lt;- paste0(\u0026#34;VIX: \u0026#34;, vix(), \u0026#34; certain amount of volatility 🦬\u0026#34;) vix_subtitle2 \u0026lt;- paste0(\u0026#34;Certain amount of volatility 🦬\u0026#34;) color \u0026lt;- \u0026#34;success\u0026#34; color \u0026lt;- \u0026#34;success\u0026#34; icon \u0026lt;- \u0026#34;happy\u0026#34; # 25-30: This can indicate that there is a certain amount of market turbulence and volatility is increasing. } else if (vix() \u0026gt; 25 \u0026amp; vix() \u0026lt;= 30) { vix_subtitle \u0026lt;- paste0(\u0026#34;VIX: \u0026#34;, vix(), \u0026#34; certain amount of market turbulence and volatility is increasing volatility ✈️\u0026#34;) vix_subtitle2 \u0026lt;- paste0(\u0026#34;Certain amount of market turbulence and volatility is increasing volatility ✈️\u0026#34;) color \u0026lt;- \u0026#34;warning\u0026#34; icon \u0026lt;- \u0026#34;sad\u0026#34; # 30 and over: This can indicate that the market is highly volatile and there may be some extreme swings soon. } else if (vix() \u0026gt; 30) { vix_subtitle \u0026lt;- paste0(\u0026#34;VIX: \u0026#34;, vix(), \u0026#34; highly volatile and extreme swings 🐻\u0026#34;) vix_subtitle2 \u0026lt;- paste0(\u0026#34;Highly volatile and extreme swings 🐻\u0026#34;) color \u0026lt;- \u0026#34;danger\u0026#34; icon \u0026lt;- \u0026#34;skull\u0026#34; } bs4ValueBox( value = tags$p(paste(\u0026#34;VIX: \u0026#34;, vix()), style = \u0026#34;font-size: 150%;\u0026#34;), subtitle = vix_subtitle2, color = color, icon = ionicon(icon) ) }) }) } Conclusion This structure keeps my Shiny applications modular, maintainable, and scalable. By separating UI logic, server logic, global functions, utility functions, and modules, I ensure better readability and reusability across projects.\nCredits Pictures Glow by Jill Wellington ","date":"2025-02-12T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/shiny-structure/orbs-4967554_1280_hu36800eac9aeb58e758f886c59cc62eea_188063_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/shiny-structure/","title":"Shiny Structure"},{"content":"Introduction There isn\u0026rsquo;t many resources on how to do view in the Phoenix framework (1.7.14) I read the official document and searched the web and it was lacking.\nEspecially on passing data onto the view template from component.\nPhoenix framework (1.7.14) is MVC but have changed the way V(view) works. So this is just a documentation for myself.\nFile Structure ./gira/*\n1 2 3 4 5 6 7 8 9 10 assets/ config/ lib/ priv/ test/ .formatter.exs .gitignore README.md mix.exs mix.lock ./gira/lib/gira_web/\n1 2 3 4 5 6 components/ controllers/ endpoint.ex gettext.ex router.ex telemetry.ex ./gira/lib/gira_web/controllers/\nNotice the page_controller.ex, page_html.ex, and page_html/.\nThe page_html.ex and page_html/ is where the \u0026ldquo;view\u0026rdquo; logics are located. This is the convention in the Phoenix framework (1.7.14) and I would suggest sticking to the default.\nAgain controllers and views lives in the controllers/ folder. View in the Phoenix framework (1.7.14) is postscript with _html and are further organized in two places.\n1 2 3 4 5 page_html/ error_html.ex error_json.ex page_controller.ex page_html.ex ./gira/lib/gira_web/components/\n1 2 3 layouts/ core_components.ex layouts.ex Codes - Simple Component for layout This is a simple component navbar that doesn\u0026rsquo;t uses any data (at least not yet). I decided to put the navbar view logic in the layout.\n./gira/lib/gira_web/components/layouts.ex\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 defmodule GiraWeb.Layouts do @moduledoc \u0026#34;\u0026#34;\u0026#34; This module holds different layouts used by your application. See the `layouts` directory for all templates available. The \u0026#34;root\u0026#34; layout is a skeleton rendered as part of the application router. The \u0026#34;app\u0026#34; layout is set as the default layout on both `use GiraWeb, :controller` and `use GiraWeb, :live_view`. \u0026#34;\u0026#34;\u0026#34; use GiraWeb, :html embed_templates \u0026#34;layouts/*\u0026#34; def navbar(assigns) do ~H\u0026#34;\u0026#34;\u0026#34; \u0026lt;nav class=\u0026#34;bg-white dark:bg-gray-900 fixed w-full z-20 top-0 start-0 border-b border-gray-200 dark:border-gray-600\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;max-w-screen-xl flex flex-wrap items-center justify-between mx-auto p-4\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;flex items-center space-x-3 rtl:space-x-reverse\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;https://flowbite.com/docs/images/logo.svg\u0026#34; class=\u0026#34;h-8\u0026#34; alt=\u0026#34;Flowbite Logo\u0026#34; /\u0026gt; \u0026lt;span class=\u0026#34;self-center text-2xl font-semibold whitespace-nowrap dark:text-white\u0026#34;\u0026gt;GiraUpdates\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;button data-collapse-toggle=\u0026#34;navbar-dropdown\u0026#34; type=\u0026#34;button\u0026#34; class=\u0026#34;inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600\u0026#34; aria-controls=\u0026#34;navbar-dropdown\u0026#34; aria-expanded=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;Open main menu\u0026lt;/span\u0026gt; \u0026lt;svg class=\u0026#34;w-5 h-5\u0026#34; aria-hidden=\u0026#34;true\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; fill=\u0026#34;none\u0026#34; viewBox=\u0026#34;0 0 17 14\u0026#34;\u0026gt; \u0026lt;path stroke=\u0026#34;currentColor\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; stroke-width=\u0026#34;2\u0026#34; d=\u0026#34;M1 1h15M1 7h15M1 13h15\u0026#34;/\u0026gt; \u0026lt;/svg\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;div class=\u0026#34;hidden w-full md:block md:w-auto\u0026#34; id=\u0026#34;navbar-dropdown\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;flex flex-col font-medium p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50 md:space-x-8 rtl:space-x-reverse md:flex-row md:mt-0 md:border-0 md:bg-white dark:bg-gray-800 md:dark:bg-gray-900 dark:border-gray-700\u0026#34;\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block py-2 px-3 text-white bg-blue-700 rounded md:bg-transparent md:text-blue-700 md:p-0 md:dark:text-blue-500 dark:bg-blue-600 md:dark:bg-transparent\u0026#34; aria-current=\u0026#34;page\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;button id=\u0026#34;dropdownNavbarLink\u0026#34; data-dropdown-toggle=\u0026#34;dropdownNavbar\u0026#34; class=\u0026#34;flex items-center justify-between w-full py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 md:w-auto dark:text-white md:dark:hover:text-blue-500 dark:focus:text-white dark:border-gray-700 dark:hover:bg-gray-700 md:dark:hover:bg-transparent\u0026#34;\u0026gt;Reading\u0026lt;svg class=\u0026#34;w-2.5 h-2.5 ms-2.5\u0026#34; aria-hidden=\u0026#34;true\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; fill=\u0026#34;none\u0026#34; viewBox=\u0026#34;0 0 10 6\u0026#34;\u0026gt; \u0026lt;path stroke=\u0026#34;currentColor\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; stroke-width=\u0026#34;2\u0026#34; d=\u0026#34;m1 1 4 4 4-4\u0026#34;/\u0026gt; \u0026lt;/svg\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;!-- Dropdown menu --\u0026gt; \u0026lt;div id=\u0026#34;dropdownNavbar\u0026#34; class=\u0026#34;z-10 hidden font-normal bg-white divide-y divide-gray-100 rounded-lg shadow w-44 dark:bg-gray-700 dark:divide-gray-600\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;py-2 text-sm text-gray-700 dark:text-gray-400\u0026#34; aria-labelledby=\u0026#34;dropdownLargeButton\u0026#34;\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block px-4 py-2 hover:bg-gray-100 dark:hover:bg-gray-600 dark:hover:text-white\u0026#34;\u0026gt;Dashboard\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block px-4 py-2 hover:bg-gray-100 dark:hover:bg-gray-600 dark:hover:text-white\u0026#34;\u0026gt;Settings\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block px-4 py-2 hover:bg-gray-100 dark:hover:bg-gray-600 dark:hover:text-white\u0026#34;\u0026gt;Earnings\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;div class=\u0026#34;py-1\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block px-4 py-2 text-sm text-gray-700 hover:bg-gray-100 dark:hover:bg-gray-600 dark:text-gray-200 dark:hover:text-white\u0026#34;\u0026gt;Sign out\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent\u0026#34;\u0026gt;Series\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent\u0026#34;\u0026gt;Tools\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent\u0026#34;\u0026gt;Login\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt; \u0026#34;\u0026#34;\u0026#34; end end ./gira/lib/gira_web/components/layouts/app.html.heex\n1 \u0026lt;.navbar /\u0026gt; Codes - Complex Component with Controller (connecting with model) This one is to have a table component, the rows are generated base on the data given by the model.\n./gira/lib/gira_web/controllers/page_controller.ex\n1 2 3 4 5 6 7 8 9 10 11 12 13 defmodule GiraWeb.PageController do use GiraWeb, :controller alias Gira.NovelUpdate #alias Gira.NovelUpdate.Update def home(conn, _params) do # The home page is often custom made, # so skip the default app layout. updates = NovelUpdate.list_updates() render(conn, :home, updates: updates) end end ./gira/lib/gira_web/controllers/page_html.ex\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 defmodule GiraWeb.PageHTML do @moduledoc \u0026#34;\u0026#34;\u0026#34; This module contains pages rendered by PageController. See the `page_html` directory for all templates available. \u0026#34;\u0026#34;\u0026#34; use GiraWeb, :html embed_templates \u0026#34;page_html/*\u0026#34; def table_update(assigns) do ~H\u0026#34;\u0026#34;\u0026#34; \u0026lt;div class=\u0026#34;relative overflow-x-auto shadow-md sm:rounded-lg\u0026#34;\u0026gt; \u0026lt;table class=\u0026#34;w-full text-sm text-left rtl:text-right text-gray-500 dark:text-gray-400\u0026#34;\u0026gt; \u0026lt;thead class=\u0026#34;text-xs text-gray-700 uppercase bg-gray-50 dark:bg-gray-700 dark:text-gray-400\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th scope=\u0026#34;col\u0026#34; class=\u0026#34;px-6 py-3\u0026#34;\u0026gt; Date \u0026lt;/th\u0026gt; \u0026lt;th scope=\u0026#34;col\u0026#34; class=\u0026#34;px-6 py-3\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;flex items-center\u0026#34;\u0026gt; Title \u0026lt;/div\u0026gt; \u0026lt;/th\u0026gt; \u0026lt;th scope=\u0026#34;col\u0026#34; class=\u0026#34;px-6 py-3\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;flex items-center\u0026#34;\u0026gt; Release \u0026lt;/div\u0026gt; \u0026lt;/th\u0026gt; \u0026lt;th scope=\u0026#34;col\u0026#34; class=\u0026#34;px-6 py-3\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;flex items-center\u0026#34;\u0026gt; Translation Group \u0026lt;/div\u0026gt; \u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr class=\u0026#34;odd:bg-white odd:dark:bg-gray-900 even:bg-gray-50 even:dark:bg-gray-800 border-b dark:border-gray-700\u0026#34; :for={update \u0026lt;- @updates}\u0026gt; \u0026lt;td class=\u0026#34;px-6 py-4\u0026#34;\u0026gt; \u0026lt;%= update.update_date %\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td scope=\u0026#34;row\u0026#34; class=\u0026#34;px-6 py-4 font-medium text-gray-900 whitespace-nowrap dark:text-white\u0026#34;\u0026gt; \u0026lt;%= update.title %\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td class=\u0026#34;px-6 py-4\u0026#34;\u0026gt; \u0026lt;%= update.release %\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td class=\u0026#34;px-6 py-4\u0026#34;\u0026gt; \u0026lt;%= update.translation_group %\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026#34;\u0026#34;\u0026#34; end end ./gira/lib/gira_web/controllers/page_html/home.html.heex\nAs of the writing this, I couldn\u0026rsquo;t find an explicit example of how to connect model data to the template and component. I\u0026rsquo;ve tried countless combination until I figured it out especially the code below.\n1 \u0026lt;.table_update updates={@updates} /\u0026gt; Credit Ai Generated Phoenix Fantasy royalty-free stock illustration. Free for use \u0026amp; download. ","date":"2024-07-22T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/phoenix-v1-7-14-views-components-and-how-it-is-different-from-other-mvc-frameworks/ai-generated-8579708_1280_hu3ed2371e628725aa6bc25e07c85826b2_263412_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/phoenix-v1-7-14-views-components-and-how-it-is-different-from-other-mvc-frameworks/","title":"Phoenix v1.7.14 Views (components) and how it is different from other MVC frameworks"},{"content":"Note: Draft, I\u0026rsquo;m not sure when I will get back to this.\nIntroducation This story happened a long time ago, 2 days ago, in a galaxy far, far away. It is already over. Nothing can be done to change it. It is a story of frustration and love for a crazy operating system on a lost technology laptop Thinkpad T400.\nInstallation Installation on 32 bit\nhttps://nixos.org/manual/nixos/stable/index.html#sec-installation\nFilesystem Chosen (BTRFS) Youtube overview on it: https://www.youtube.com/watch?v=iwNg_fusT9A\nEncryption: https://www.youtube.com/watch?v=co5V2YmFVEE\nFS questions What are subvolumes in BTRFS? What software/apps is recommended for BTRFS? (Esp. Defrag. Look at OpenSUSE app) How large my /swap be if I have 64 GB of RAM? https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-swapspace\nAt least 4GB.\nhttps://superuser.com/questions/777907/swap-partition-size-on-a-64-gb-ram-computer-for-memory-intensive-work\n16GB\nWhat\u0026rsquo;s Impermanence means in NixOS? https://discourse.nixos.org/t/what-does-impermanence-add-over-built-in-functionality/27939\n\u0026ldquo;The idea of impermanence is that upon reboot, the machine loses its state and in the case of NixOS gets recreated from your configuration (stored in a persistent area of your file system). So any erroneous state changes (accidental or otherwise) are lost between reboots. The persistent area will hold some important data - perhaps ssh keys (depending on type) and passwords that you may need beyond your configuration.nix (or flake) It does not affect your home folders. I found Guekka’s blog are good resource - NixOS as a server, part 1: Impermanence | Guekka\u0026rsquo;s blog I use it - as much to find out more about it as anything else. If it interests you, try on a spare machine first.\u0026rdquo;\n\u0026ndash; Damage May 7, 2023, 7:45pm 2\nNixOS\u0026rsquo;s Wiki BTRFS layout recommendations https://nixos.wiki/wiki/Btrfs\n#5: How do you encrypt?\nhttps://wiki.nixos.org/wiki/Btrfs#Installation_with_encryption\n","date":"2024-03-20T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/nixos-a-new-journey/nixos-logo_hu94391645a48d560a063197e47ffd56ad_39259_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/nixos-a-new-journey/","title":"NixOS: A new journey"},{"content":"Note: Draft, not sure when I\u0026rsquo;ll continue this.\nIntroduction Firstly, I want to thank House of Dim and his tutorial. It was this video that got me started with AnimateDiff.\nFirst Workflow Animate Prep Workflow: https://github.com/Dimgul/ComfyUI-Workflows/blob/main/house_of_dim_animate_prep_workflow.json\nCredits Dancing picture was created by me using stable diffusion ComfyUI + AnimateDiff + ControlNets Workflow by House of Dim Animate Prep Workflow: https://github.com/Dimgul/ComfyUI-Workflows/blob/main/house_of_dim_animate_prep_workflow.json AnimateDiff+ControlNets Workflow: https://github.com/Dimgul/ComfyUI-Workflows/blob/main/house_of_dim_animate_workflow.json ","date":"2024-01-22T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/my-current-comfyui-and-animatediff-workflow/dance_053_hu71ab205c8a698e86a3463b32c5f1d3c3_128035_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/my-current-comfyui-and-animatediff-workflow/","title":"My current ComfyUI and AnimateDiff workflow (and How to set it up)"},{"content":"Objective Just to document my set up so I can come back and refer to it. And for this to be newbie friendly.\nTo set up an online cloud environment to run Stable Diffusion to create AI video (with ComfyUI and AnimateDiff).\nIt would save me money via:\nElectricity Cost Graphic Card (which will depreciate overtime with new technology) Real life reason:\nI ran out of memory and it crash my queue when I was doing AnimateDiff. 6GB VRAM on my laptop wasn\u0026rsquo;t enough and it took over 16 hours to run a partial portion of it.\nCloud Provider https://www.runpod.io/\nI use Runpod because that\u0026rsquo;s the first option I\u0026rsquo;ve found.\nI also found a tutorial on setup via youtube: ComfyUI AnimateDiff Prompt Travel: Runpod.io Cloud GPUs Tutorial by c0nsumption\nSetting up a Pod (a GPU cloud instance) To start spinning up a new instance first click on the \u0026lsquo;New Pod\u0026rsquo; option over at the console.\nPod Console Pod Template Make sure Pod Template is set to: \u0026lsquo;RunPod SD Comfy UI\u0026rsquo;\nPod Cloud Type Select cloud type using the Cloud Type drop down filter menu. I chose the \u0026lsquo;Community Cloud\u0026rsquo; option because it\u0026rsquo;s cheaper.\nSelect GPU I chose this option for my first run.\nClick the option, \u0026lsquo;Customize Deployment\u0026rsquo;.\nAnd change Container Disk to 25GB. Some installation package will eat up more than 5GB (default).\nClick the option, \u0026lsquo;Deploy\u0026rsquo;.\nYou will end up with the next menu, check all the option is correct. Make sure the \u0026lsquo;Start Jupyter Notebook\u0026rsquo; checkbox is checked. Once confirming that the GPU instance configurations is correct click on the button, \u0026lsquo;Continue\u0026rsquo;.\nDeploy GPU Instance Look over the pricing summary for the extra/hidden cost on top of the GPU pricing rate. Once you\u0026rsquo;re okay with the total cost, click on the button \u0026lsquo;Deploy\u0026rsquo;.\nIt\u0026rsquo;ll redirect you to the Pod Console where your new instance is now created but not started.\nMore info on the pod by clicking the purple arrow button.\nPod Customization Set up ComfyUI port 8188 IMPORTANT\nClick on the hamburger button (the three horizontal line button) aka More Actions.\nSelect \u0026lsquo;Edit Pod\u0026rsquo;.\nYou should get this menu.\nFrom the menu above, locate \u0026lsquo;Expose TCP Ports\u0026rsquo;. Add 8188 to that field. Note you should now have \u0026lsquo;22,8188\u0026rsquo; (see picture below). Port 8188 is the default ComfyUI port. Click Save.\nPod ComfyUI Setup Connect to Juypter Click on the \u0026lsquo;Connect\u0026rsquo;.\nYou\u0026rsquo;ll get this menu:\nSelect the option Connect to Jupyter Lab [Port 8888]. This will open a new tab in your browser with Jupyter Lab.\nJupyter Lab Terminal From the Other menu, select the Terminal option.\nFrom here you should get this terminal:\nNOTE/WARNING: Anything in the /workspace directory will persist and exist after you stop your instance. Anything outside of this folder will not persist.\nSetup Python Virtual Environment Type below into Jupyter\u0026rsquo;s terminal:\n1 python -m venv venv Activate virtual environment:\n1 source venv/bin/activate Latest ComfyUI version Get the latest ComfyUI version.\n1 2 cd /workspace/ComfyUI git pull ComfyUI setup Nvidia Following the Linux Nvidia installation instruction.\nType the commands below in Jupyter Terminal:\n1 2 cd ComfyUI pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121 Then do this:\n1 pip install -r requirements.txt ComfyUI Manager Installation Go to the custom_nodes folder:\n1 cd /workspace/ComfyUI/custom_nodes/ Once in the custom_nodes folder, we going to do git clone.\n1 git clone https://github.com/ltdrdata/ComfyUI-Manager.git Start ComfyUI 1 2 cd /workspace/ComfyUI/ python main.py --listen Connect to ComfyUI Go back to Pod Console, click on the Connect button.\nNotice the Public IP and External port across from Internal port 8188 (ComfyUI default port).\nThat\u0026rsquo;s how you get you to comfyui in your browser:\nPublic IP:External\nPublic IP:40007\nDownload Models from Civic AI Make sure you close ComfyUI if it\u0026rsquo;s running.\nAt the Jupyter Terminal shortcut, Ctrl + c.\nGo to the ComfyUI models folder:\n1 cd /workspace/ComfyUI/models Checkpoint Models Go to checkpoint model directory:\n1 cd /workspace/ComfyUI/models/checkpoints You can list all that\u0026rsquo;s inside the folder with ls.\nGo to Civic AI and find a checkpoint model you like Make a Civic AI account (it\u0026rsquo;s free).\nFor the search option click on the Filters option.\nThese are all the options in the Filters option menu (make sure you scroll down for more options):\nMy chosen checkpoint, GhostMix, for this tutorial:\nClick on it to head to the main page of chosen checkpoint.\nright click on the Download button and select Copy Link.\nThe link address should be copied and it should be this:\n1 https://civitai.com/api/download/models/76907 Find out the file name of the check point by downloading it to local computer and cancel the download:\nFile name:\nghostmix_v20Bakedvae.safetensors\nDownload Chosen Checkpoint into your pod Head over to your pod Jupyter Notebook\u0026rsquo;s terminal.\nMake sure you are in the checkpoint folder.\n1 cd /workspace/ComfyUI/models/checkpoints Now download the chosen model:\n1 wget -O ghostmix_v20Bakedvae.safetensors https://civitai.com/api/download/models/76907 So the format is:\n1 wget -O filename_with_extension model_url Type ls to make sure the model is downloaded.\nStarting Workflow Start up Python\u0026rsquo;s virtual environment 1 source venv/bin/activate Start up ComfyUI 1 2 cd /workspace/ComfyUI/ python main.py --listen `\nConclusion So that\u0026rsquo;s basically it for the set up.\nNow you need a workflow and download models that the workflow require. I\u0026rsquo;ll make another post on AnimateDiff workflow using this base setup.\nCredits Vampire Elf picture: created by me using Stable Diffusion and A1111. ComfyUI AnimateDiff Prompt Travel: Runpod.io Cloud GPUs Tutorial by c0nsumption ","date":"2024-01-21T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/stable-diffusion-in-the-cloud-set-up/vampire_elf_hu698cc1e37a206339e30a863b9b5838e5_69657_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/stable-diffusion-in-the-cloud-set-up/","title":"Stable Diffusion in the Cloud Set up"},{"content":"Note: Draft, not sure when I\u0026rsquo;ll come back to continue this.\nGoal To create a tutorial for myself so I can come back to.\nI have a passion for dancing and I\u0026rsquo;d want to make AI instagram video of myself dancing.\nPreprocessing video Softwares Needed Handbrake DaVinci Resolve Steps Credit: ComfyUI + AnimateDiff + ControlNets Workflow by House of Dim\nGet a Video you want to AI If it\u0026rsquo;s Iphone you need 1. Qubii; to back up into sd 2. a SD card reader to read from laptop. Get HandBrake; use this to convert your iphone video to mp4, so DaVinci Resolve can actually read the codec. Window cannot read Apple\u0026rsquo;s MOV video. Get DaVinci Resolve (free) In DaVinci Resolve go to Project Settings menu (File -\u0026gt; Project Settings). From here make sure the resolution is 1080 x 1920 HD (for instagram reel). Make sure to check the checkbox for \u0026lsquo;Use vertical resolution\u0026rsquo; for portrait mode. Make sure the \u0026lsquo;Playback frame rate\u0026rsquo; option is at \u0026lsquo;24\u0026rsquo; frames per second. Go to the \u0026lsquo;Edit\u0026rsquo; tab. The tab menu are at the bottom. From here locate the \u0026lsquo;Master\u0026rsquo; panel. Right click on the \u0026lsquo;Master\u0026rsquo; panel to get a drop down menu. Select the option \u0026lsquo;Import Media\u0026hellip;\u0026rsquo; from the right click drop down menu. Select the video you want to AI Drag and drop this video into the timeline panel To trim the video: On the timeline panel left side move the verticle red line forward to where you want your video to start. Then to trim the left side you do shortcut key \u0026lsquo;Ctrl + Shift + [\u0026rsquo; For the right side, ending trim, same thing but the short cut key is \u0026lsquo;Ctrl + Shift + ]\u0026rsquo; 9. top right panel \u0026lsquo;inspector\u0026rsquo; 10. bottom tab deliver set format to \u0026lsquo;JPEG\u0026rsquo;\n","date":"2024-01-20T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/my-comfyui-animatediff-controlnets-workflow/","title":"My ComfyUI, AnimateDiff, ControlNets Workflow"},{"content":"Note: Draft, not sure when I\u0026rsquo;ll come back and continue this.\nCredits Make your WSL or WSL2 terminal awesome - with Windows Terminal, zsh, oh-my-zsh and Powerlevel10k by Christian Lempa Nerd Fonts Windows Package Manager, Winget Winget Docs Windows Terminal WSL WSL issue WSL Update ","date":"2023-11-30T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/configuring-window-10-to-be-more-developer-friendly/","title":"Configuring Window 10 to be more developer friendly"},{"content":"NOTE: DRAFT, not sure when I\u0026rsquo;ll come back to continue this.\nTypes and Domains TYPES AND RELATIONS Data types (types for short) are fundamental to computer science. Every attribute of every relation is defined to be of some type, and the same is true of relvars.\nA relational attribute (i.e., an attribute of a relation or relvar) can be of any type whatsoever, implying among other things that such types can be arbitrarily complex. In particular, those types can be either system or user defined.\nTwo major topics:\nEquality comparisons and “domain check override”: That domains really are types. Data value atomicity and first normal form: That the types in question can be arbitrarily complex. EQUALITY COMPARISONS The Main Differences Between an Expression and a Statement in Programming. Expressions can be assigned or used as operands, while statements can only be declared. Statements create side effects to be useful, while expressions are values or execute to values.\nTHE_ operators, effectively provides both (a) the domain checking we want in the first place and (b) a way of overriding that checking, when desired, in the second place\nstrong typing. - (a) everything—in particular, every value and every variable—has a type, and (b) whenever we try to perform some operation, the system checks that the operands are of the right types for the operation in question (or, possibly, that they’re coercible to those right types). Observe, moreover, that this mechanism works for all operations, not just for the equality comparisons\nDATA VALUE ATOMICITY data value atomicity and the related notion of first normal form (1NF for short).\n1NF meant that every tuple in every relation contains just a single value (of the appropriate type) in every attribute position—and it’s usual to add that those “single values” are supposed to be “atomic.\nWhat does it mean for data to be atomic?\nCodd defines atomic data as data that “cannot be decomposed into smaller pieces by the DBMS (excluding certain special functions).”\nthe notion of atomicity has no absolute meaning; it just depends on what we want to do with the data.\nWHAT’S A TYPE? So what is a type, exactly? In essence, it’s a named, finite set of values—all possible values of some specific kind.\nTo elaborate briefly:\nThe types we’re interested in are always finite because we’re dealing with computers,which (as pointed out in connection with type RATIONAL earlier in the chapter) are finite by definition. Note also that qualifier named: Types with different names are different types. Moreover:\nEvery value is of some type — in fact, of exactly one type, except possibly if type inheritance is supported, a concept that’s beyond the scope of this book. Every variable, every attribute, every operator that returns a result, and every parameter of every operator is defined, or declared, to be of some type. 10 And to say that, e.g., variable V is declared to be of type T means, precisely, that every value v that can legally be assigned to V is in turn of type T. Every expression denotes some value and is therefore of some type: namely, the type of the value in question, which is to say the type of the value returned by the outermost operator in the expression (where by “outermost” I mean the operator that’s executed last). For example, the type of the expression ( a / b ) + ( x - y ) is the type declared for the operator “+”, whatever that happens to be. associated with every type there’s a set of operators for operating on values and variables of the type in question — where to say that operator Op is “associated with” type T basically just means that operator Op has a parameter of type T\nThat defining a new type involves at least all of the following:\nDefining a name for the type (obviously enough). Defining the values that make up that type. I’ll discuss this aspect in detail in Chapter 8. Defining the hidden physical representation for values of that type. As noted earlier, this is an implementation issue, not a model issue, and I won’t discuss it further in this book (at least, not much). Defining one or more selector operators for selecting, or specifying, values of that type. Note: Here’s as good a place as any to point out in the interest of accuracy that the selectors for type T aren’t “associated with” type T in the sense that they have a parameter of type T; rather, they return a result of type T. Defining the operators, including in particular assignment (“:=”), equality comparison (“=”), and THE_ operators, that apply to values and variables of that type (see below). For those operators that return a result, defining the type of that result (again, see below). points 4, 5, and 6 taken together imply that (a) the system knows precisely which expressions are legal, and (b) for those expressions that are legal it knows the type of the result as well.\nSCALAR vs. NONSCALAR TYPES Types are frequently said to be either scalar or nonscalar. Loosely, a type is scalar if it has no user visible components and nonscalar otherwise.\nscalar - types that are neither tuple nor relation types. nonscalar - types that are either tuple or relation types. A generated type is a type that’s obtained by invoking some type generator (in the example, the type generator is, specifically, RELATION). You can think of a type generator as a special kind of operator; it’s special because (a) it returns a type instead of a value, and (b) it’s invoked at compile time instead of run time. For instance, most programming languages support a type generator called ARRAY, which lets users define a variety of specific array types. For present purposes, however, the only type generators we’re interested in are TUPLE and RELATION. Finally, a few miscellaneous points to close this section:\nEven though tuple and relation types do have user visible components (namely, their attributes), there’s no suggestion that those components have to be physically stored as such, in the form in which they’re seen by the user. In fact, the physical representation of tuples and relations should be hidden from the user, just as it is for scalar values (recall the discussion of physical data independence in Chapter 1). Like scalar types, tuple and relation types certainly need associated selector operators (and literals as a special case). I’ll defer the details to the next chapter. They don’t need THE_ operators, however; instead, they have operators that provide access to the corresponding attributes, and those operators play a role somewhat analogous to that played by THE_ operators in connection with scalar types. Tuple and relation types also need assignment and equality comparison operators. I gave an example of tuple assignment earlier in the present section; I’ll defer details of the other operators—relational assignment, and tuple and relational equality comparisons—to the next chapter. SCALAR TYPES IN SQL SQL supports the following more or less self-explanatory system defined scalar types:\nBOOLEAN INTEGER SMALLINT BIGINT NUMERIC(p,q) DECIMAL(p,q) FLOAT(p) CHARACTER(n) CHARACTER VARYING(n) CHARACTER LARGE OBJECT(n) BINARY(n) BINARY VARYING(n) BINARY LARGE OBJECT(n) DATE TIME TIMESTAMP INTERVAL XML TYPE CHECKING AND COERCION IN SQL SQL supports only a weak form of strong typing.\nThus, for example, an attempt to compare a number and a character string is illegal.\nHowever, an attempt to compare (say) two numbers is legal, even if those numbers are of different types—say INTEGER and FLOAT.\nStrong recommendations: Do your best to avoid coercions wherever possible. columns with the same name are always of the same type; And when they can’t be avoided, I recommend doing them explicitly, using CAST or some CAST equivalent\nCertain coercions are unfortunately built into the very fabric of SQL and so can’t be avoided. To be specific:\nIf a table expression tx is used as a row subquery, then the table t denoted by tx is supposed to have just one row r, and that table t is coerced to that row r. If a table expression tx is used as a scalar subquery, then the table t denoted by tx is supposed to have just one column and just one row and hence to contain just one value v, and that table t is doubly coerced to that value v. Note: This case occurs in connection with SQL-style aggregation in particular (see Chapter 7). In practice, the row expression rx in the ALL or ANY comparison rx θ sq—where (a) θ is a simple scalar comparison operator, such as “\u0026lt;” or “\u0026gt;”, followed by the keyword ALL or ANY, and (b) sq is a subquery—often consists of a simple scalar expression, in which case the scalar value denoted by that expression is effectively coerced to a row that contains just that scalar value. Note: Throughout this book, I use the term row expression to mean either a row subquery or a row selector invocation (where row selector in turn is my preferred term for what SQL calls a row value constructor—see Chapter 3); in other words, I use row expression to mean any expression that denotes a row, just as I use table expression to mean any expression that denotes a table. As for ALL or ANY comparisons, they’re discussed in Chapter 11. COLLATIONS IN SQL A collation— also known as a collating sequence—is a rule that’s associated with a specific character set and governs the comparison of strings of characters from that character set. Let C be a collation for character set S, and let a and b be any two characters from S. Then C must be such that exactly one of the comparisons a \u0026lt; b, a = b, and a \u0026gt; b evaluates to TRUE and the other two to FALSE (under C).\nRecommendation: Don’t use PAD SPACE—always use NO PAD instead, if possible.\nStrong recommendation: Avoid possibly nondeterministic expressions as much as you can.\nROW AND TABLE TYPES IN SQL SQL ROW type generator (type constructor):\n1 2 3 4 5 DECLARE SRV # SQL row variable ROW ( SNO VARCHAR(5) , SNAME VARCHAR(25) , STATUS INTEGER , CITY VARCHAR(20) ) ; SQL row assignment:\n1 SET SRV = ( S WHERE SNO = \u0026#39;S1\u0026#39; ) ; SQL doesn\u0026rsquo;t really have a TABLE type generator.\nCREATE TABLE for defining table variables.\n1 2 3 4 5 6 CREATE TABLE S ( SNO VARCHAR(5) NOT NULL , SNAME VARCHAR(25) NOT NULL , STATUS INTEGER NOT NULL , CITY VARCHAR(20) NOT NULL , UNIQUE ( SNO ) ) ; Type tables. Strong recommendation: Don\u0026rsquo;t use them, nor any features related to them.\nCONCLUDING REMARKS Relations can have attributes of any type whatsoever. The question as to what types are supported is orthogonal to the question of support for the relational model itself. First normal form just means that every tuple in every relation contains a single value, of the appropriate type, in every attribute position. Certain important exceptions to the rule that relational attributes can be of any type whatsoever. Two exceptions: The first is that if relation r is of type T, then no attribute of r can itself be of type T (think about it!). The second (which in fact I’ve already touched on) is that no relation in the database can have an attribute of any pointer type. Credits First picture (tables): https://pixabay.com/illustrations/village-city-coast-colorful-houses-8396532/ https://pixabay.com/photos/sees-it-relation-relationship-soul-4138304/ https://pixabay.com/photos/atom-nuclear-power-plant-abandoned-3669818/ https://pixabay.com/photos/stop-violence-abuse-partner-1971756/ - This is the only one out of a few choices that had some sembalence of sense for Coercion. Plus I love Kermit. https://pixabay.com/photos/sunrise-boat-rowing-boat-nobody-1014712/ https://pixabay.com/photos/typewriter-vintage-old-1248088/ ","date":"2023-11-22T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/book-notes-sql-and-relational-theory-chp2/village-8396532_1280_hue1ddd2565bae2c38352275251d9b80ad_171484_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/book-notes-sql-and-relational-theory-chp2/","title":"Book Notes: SQL and Relational Theory (3rd ed) by C.J. Date, Chp 2 - Types and Domains - Notes"},{"content":"Note: DRAFT\nIntroduction Started reading \u0026ldquo;SQL and Relational Theory\u0026rdquo; by C.J. Date.\nIt\u0026rsquo;s been awhile since I\u0026rsquo;ve dealt with Relational Theory so I\u0026rsquo;m taking notes since their terminology is different than SQL. I also have a strange style of learning which requires physically doing something on top of visually reading. This is the physical part.\nOriginal Model Terminology The original model by E. F. Codd had three major components:\nstructure, integrity, and manipulation. Structural Features Relation (\u0026quot;table\u0026quot;) - are defined over types Attribute (\u0026quot;column\u0026quot;) Type (\u0026quot;column values\u0026quot; aka \u0026ldquo;domain\u0026rdquo;) - a conceptual pool of values from which actual attributes in actual relations take their actual values. N-ary relation - # of column in a table Candidate key (\u0026quot;key\u0026quot;) - every relation has at least one. A combination of attributes (cols), often just 1 attribute (e.g. column with id\u0026rsquo;s), such that every tuple in the relation has a unique value for the combinatoin in question. Primary key - is a candidate key that\u0026rsquo;s been singled out for special trestment in some way. Foreign key - a combination, or set, of attributes FK in some relation r2 such that each FK value is required to be equal to some value of some key K in some relation r1. Constraint (aka integrity constraint) - a boolean expression that must evaluate to TRUE. Integrity Features The Entity Integrity Rule - Primary key attributes don\u0026rsquo;t permit NULL\u0026rsquo;s. The Referential Integrity Rule - There mustn\u0026rsquo;t be any unmatched foreign key values. If B references A, then A must exists. Manipulative Features Relational algebra - a collection of operators (e.g., difference, or MINUS) that can be applied to relations (tables). Allows us to derived \u0026ldquo;new\u0026rdquo; relations from \u0026ldquo;old\u0026rdquo; ones. Relational assignment operator - allows the value of some relational algebra expression (e.g., r1 MINUS r2, where r1 and r2 are relations) to be assigned to some relation (table). How updates are done in the relational model.Update means INSERT, DELETE, and UPDATE operators. Closure property - The output from every operation is the same kind of thing as the input, the out put from one peration can become the input to another. Enable us to wrjite nested relational expressions. Original Operators* *the ones that Codd defined in his earliest papers\nRestrict - Returns a relation containing all tuples from a specified relation that satisfy a specified condition. For example, we might restrict relation EMP to just those tuples where the DNO value is D2. My Note: this seems like a WHERE clause. Project - Returns a relation containing all (sub)tuples that remain in a specified relation after specified attributes have been removed. For example, we might project relation EMP on just the ENO and SALARY attributes (thereby removing the ENAME and DNO attributes). My Notes: SELECT statement, where you specified which column(s) you want. Product - Returns a relation containing all possible tuples that are a combination of two tuples, one from each of two specified relations. Note: TRhis operator is also known variously as cartesian product (sometimes more specifically extended or expanded cartesian product), cross product,cross join, and cartesian join; in fact it\u0026rsquo;s really just a special case of join (see chp 6). Union - Returns a relation containing all tuples that appear in either or both of two specified relations. Intersect - Returns a relation containing all tuples that appear in both of two specified relations (special case of join). Difference - Returns a relation containing all tuples that appear in the first and not the second of specified relations. Join - Returns a relation containing all possible tuples that are a combination of two tuples, one from each of two specified relations, such that the two tuples contributing to any given result tuple have a common value for the common attributes of the two relations (and that common value appears just once, not twice, in that result tuple). Note: This kind of join was originally called the natural join, to distinguish it from various other kinds. This is the most inportant join so join means natural join. Note: Relational Calculus is an alternative to Relational Algebra.\nData Model vs Implementation A data model (first sense) is an abstract, self-contained, logical definition of the data structures, data operators, and so forth, that together make up the abstract machine with which users interact. The model (first sense) is what the user has to know. An implementation of a given data model (first sense) is a physical realization on a real machine of the components of the abstract machine that together constitute that model. The implementation is what the user doesn’t have to know. Physical data independence - means we have the freedom to make changes in the way the data is physically stored and accessed without having to make corresponding changes in the way the data is perceived by the user. \u0026hellip;means protecting investment in user training and applications. A data model (second sense) is a model of the data—especially the persistent data—of some particular enterprise. Is just a logical, and possibly somewhat abstract, database design. A domain can be thought of as a conceptual pool of values from which actual attributes in actual relations take their actual values. In other words, a domain is a type, and the terms domain and type are effectively interchangeable. Data Model (first sense) vs Data Model (second sense) A data model in the first sense is like a programming language, whose constructs can be used to solve many specific problems but in and of themselves have no direct connection with any such specific problem. A data model in the second sense is like a specific program written in that language—it uses the facilities provided by the model, in the first sense of that term, to solve some specific problem. PROPERTIES OF RELATIONS First of all, every relation has a heading and a body:\nHeading is a set of attributes (where by the term attribute I mean, very specifically, an attribute-name : type-name pair, and where no two attributes in the same heading have the same attribute name).\nBody is a set of tuples that conform to that heading.\nDegree (aka arity) is the number of attributes in the heading, both of that heading as such and of any relation that has that heading.\nCardinality is the number of tuples in the body, both of the body itself and of the relation that contains it.\nRelations never contain duplicate tuples. SQL tables are allowed to contain duplicate rows and thus aren’t relations, in general.\nThe tuples of a relation are unordered. ORDER BY is useful for displaying results, but it isn’t a relational operator as such.\nRelations are always normalized (equivalently, they’re in first normal form, 1NF).\nSome Crucial Points Every subset of a tuple is a tuple. Every subset of a heading is a heading. Every subset of a body is a body. Equality:\ntwo tuples are duplicates of each other if and only if they’re equal: in other words, if and only if they’re the very same tuple. two relations are equal if and only if, in turn, their headings are equal and their bodies are equal. BASE vs. DERIVED RELATIONS The operators of the relational algebra allow us to start with some given relations and obtain further relations from those given ones.\nThe given relations are referred to as base relations, the others are derived relations.\nCREATE TABLE SQL statement - creates base relations. CREATE VIEW SQL statement - is one way to create derived relations. A view (also known as a virtual relation) is a named relation whose value at any given time t is the result of evaluating a certain relational expression at that time t. Can think of a view as being “materialized”—in effect, you can think of a base relation being constructed whose value is obtained by evaluating the specified relational expression—at the time the view in question is referenced. Note: Relational model has nothing to say about physical storage matters at all.\nNote: a view is that it is a table/relation. Don\u0026rsquo;t treat it any differently when come to relational algebra on view vs table/relation.\nRELATIONS vs. RELVARS VALUES vs. VARIABLES A value is an “individual constant” (this is the term used by logicians), such as the integer 3. A value has no location in time or space. However, values can be represented in memory by means of some encoding, and those representations or encodings do have location in time and space. Indeed, distinct representations of the same value can appear at any number of distinct locations in time and space—meaning, loosely, that any number of different variables (see the definition immediately following) can have the same value, at the same time or different times. Observe in particular that, by definition, a value can’t be updated; for if it could, then after such an update it wouldn’t be that value any longer. A variable is a holder for a representation of a value. A variable does have location in time and space. Also, variables, unlike values, can be updated; that is, the current value of the variable can be replaced by another value. (After all, that’s what “variable” means—to be a variable is to be updatable, to be updatable is to be a variable; equivalently, to be a variable is to be assignable to, to be assignable to is to be a variable.) CONCLUDING REMARKS Relations have no duplicate tuples, no top to bottom tuple ordering, and no left to right attribute ordering. Overall, the relational model is declarative, not procedural, in nature; that is, it always favors declarative solutions over procedural ones, wherever such solutions are feasible. Declarative means the system does the work. Procedural means the user does the work. Credits First picture (tables): database-schema-data-tables-schema-1895779 ","date":"2023-11-21T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/book-notes-sql-and-relational-theory-chp1/database-schema-1895779_1280_huac3e39f9b8c6552b2a8f76d2e5316d9f_72957_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/book-notes-sql-and-relational-theory-chp1/","title":"Book Notes: SQL and Relational Theory (3rd ed) by C.J. Date, Chp 1 - Setting the Scene - Notes"},{"content":"Current Webstack 2023 Elixir I enjoy the programming language. It\u0026rsquo;s fun and it\u0026rsquo;s mostly complete as quoted by Jose Valim (the creator of Elixir).\nThere are mostly improvements for developers like debugging and bug fixes.\nJose Valim have been working hard and in a few years or so maybe we get type in Elixir. It\u0026rsquo;s not guarantee but he have been talking about his work.\nOne thing is there are like three version managers for managing Elixir and Erlang versions now.\nasdf - install and manage different Elixir and Erlang versions kiex - install and manage different Elixir versions kerl - install and manage different Erlang versions Phoenix Framework It\u0026rsquo;s getting better.\nDeployment is mix release 1 instead of using edeliver.\nThe framework have built in log-in now. Back then there were so many third party log-in options. It was hectic just trying to figure it out and integrate it.\nJavascript Just plain vanilla Javascript. I am not really into front end as much and don\u0026rsquo;t have much time for it. Been doing a lot of statistic, data science, and machine learning stuff.\nJQuery I\u0026rsquo;m going to stick with what I know. End users doesn\u0026rsquo;t care about the tech you use. It works and I\u0026rsquo;d like to quickly bring up a project.\nBootstrap Same reason as above.\nPostgreSQL PostgreSQL is still my favorite RMDB.\nLinux (Debian) Debian is rock solid as a server OS. It\u0026rsquo;s either this or Ubuntu. It doesn\u0026rsquo;t matter much for me.\nIDE VIM \u0026amp; Tmux These two in tandem is my go to for web development.\nFuture Tailwind CSS I\u0026rsquo;d like to move to Tailwind CSS. They already name all the things you need and you don\u0026rsquo;t have to come up with any. It may looks ugly html but I don\u0026rsquo;t mind it. I don\u0026rsquo;t mind html tag having tons of classes.\nIt also remove zombie classes too. Zombie classes are classes that are defined but not used.\nPhoenix LiveView Can reduce Javascript codes. I\u0026rsquo;d like to use as little javascript as possible and more Elixir instead.\nIt\u0026rsquo;s not 1.0 yet and even then it\u0026rsquo;s probably not perfect. I\u0026rsquo;ll play around just to stay ahead and keep a general idea where it\u0026rsquo;s going.\nIDE VS Studio Code It\u0026rsquo;s a good IDE for tailwind css integration (autocomplete and suggestions).\nFly.io Manage server and back end for me. Less system admin tasks eating my time and it\u0026rsquo;ll let me concentrate on iterating and getting the project out.\nSummary At the end of the day, I am tired of trying to get the ideal tech stack and get everything perfect.\nI just want to have a product out.\nGet people to use it and iterate the product.\nOnce and if the product is flesh out then I\u0026rsquo;ll worry about perfection.\nAt this point my mindset is my code will be toss out within 5 years for a rewrite either adopting a new tech or update. So don\u0026rsquo;t worry about perfection.\nCredit Ghost In The Shell Ghost Shell ","date":"2023-11-17T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/my-web-stack-in-the-year-2023-and-the-future/ghost-in-the-shell-7765132_1280_hu2ae759ce12b03dce750ac36f7d6b378c_337571_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/my-web-stack-in-the-year-2023-and-the-future/","title":"My Web Stack in the year 2023 and the future"},{"content":"Intro I\u0026rsquo;ve been doing side project. One of the area I am interested in financial securities mostly stocks, ETFs, REITs, and options.\nI came across congress financial security trading records. I cleaned the data and currently figuring out what the response / outcome column is.\nI came across a few R packages along the way that have been useful for me for this endearvour and I\u0026rsquo;d like to share them. All these R packages was found through a youtube tutorial.\nPackages RQuantLib Package This package is very useful for getting and finding all trading dates of the US market.\nExample:\n1 2 3 4 5 6 # 2023-11-15 - Wednesday # 2023-11-12 - Sunday RQuantLib::isBusinessDay( calendar = \u0026#34;UnitedStates/NYSE\u0026#34;, dates = as.Date(c(\u0026#39;2023-11-15\u0026#39;,\u0026#39;2023-11-12\u0026#39;))) # Output: [1] TRUE FALSE Source: https://github.com/eddelbuettel/rquantlib\nOf course Dirk Eddelbuettel is involved. The dude is a legend in R circle (and anything related to C++ and R crossover).\nrvest Package It\u0026rsquo;s a webscraping package.\nI used this to grab the EPS and earning dates to create a response/outcome variable for congress trading dataset.\nCredit for the code. quantRoom youtube.\nExample:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ### # get EPS by Ticker - includes Earning date ### getEPS \u0026lt;- function(ticker) { Sys.sleep(3) url \u0026lt;- paste0( \u0026#34;https://finance.yahoo.com/calendar/earnings/?symbol=\u0026#34;, ticker) # read in page html pg \u0026lt;- rvest::read_html(url) # locate table TABLE \u0026lt;- pg %\u0026gt;% rvest::html_nodes(\u0026#34;table\u0026#34;) %\u0026gt;% rvest::html_table() # row bind results and convert to data.frame TABLE \u0026lt;- as.data.frame(t(do.call(rbind,TABLE[[1]]))) # remove timezone from Earnings Date TABLE$`Earnings Date` \u0026lt;- gsub(\u0026#34;EST\u0026#34;,\u0026#34;\u0026#34;,TABLE$`Earnings Date`) TABLE$`Earnings Date` \u0026lt;- gsub(\u0026#34;EDT\u0026#34;,\u0026#34;\u0026#34;,TABLE$`Earnings Date`) # fix Earning Date/time TABLE$`Earnings Date` \u0026lt;- as.POSIXct(TABLE$`Earnings Date`, format = \u0026#34;%b %d, %Y, %I %p\u0026#34;, tz = \u0026#34;EST\u0026#34;) # fix EPS TABLE$`EPS Estimate` \u0026lt;- as.numeric(TABLE$`EPS Estimate`) %\u0026gt;% suppressWarnings() TABLE$`Reported EPS` \u0026lt;- as.numeric(TABLE$`Reported EPS`) %\u0026gt;% suppressWarnings() # fix earning surprise percentage TABLE$`Surprise(%)` \u0026lt;- ( as.numeric(gsub(\u0026#34;\\\\+\u0026#34;,\u0026#34;\u0026#34;,TABLE$`Surprise(%)`)) %\u0026gt;% suppressWarnings() )/100 # return ALL TABLE } EPS \u0026lt;- getEPS(ticker=\u0026#34;ADM\u0026#34;) Source: https://rvest.tidyverse.org/\nCredits Pictures Bear \u0026amp; Baby https://pixabay.com/illustrations/toddler-baby-teddy-bear-cute-stars-8297939/ Gifts https://pixabay.com/photos/gift-package-ribbon-parcel-444520/ Code tutorial quantRoom youtube. ","date":"2023-11-15T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/useful-r-packages-i-ve-come-across/gift-444520_640_hu8aa387175768c8b2bcaf144681e43f89_89602_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/useful-r-packages-i-ve-come-across/","title":"Useful Financial R packages I've come across"},{"content":"Step 1: Create your Digital Ocean droplet Make sure you add your SSH when creating digital ocean and do not add a paraphrase to your SSH. It doesn’t work with paraphrase.\nStep 2: Setting up your server (DO droplet) Log into your server. 1 ssh root@134.209.8.141 Setup VIM as default editor on your server. 1 sudo update-alternatives --config editor Make sure you select the /usr/bin/vim.basic option which is number 3.\nUpdate your locale. 1 2 sudo update-locale LC_ALL=en_US.UTF-8 sudo update-locale LANGUAGE=en_US.UTF-8 Create new deploy user The next step is to create a non-root user on the server which will own our application and handle deployments. We’ll configure the .ssh directory for the user, configure the user to have passwordless sudo access, and disabled password login to harden the server a bit.\nLet’s create the user deploy.\nAs root on the target server:\n1 adduser deploy Fill out the data as required. Like password.\nNext, run this series of commands to configure the user’s .ssh directory:\n1 2 3 4 5 sudo mkdir -p /home/deploy/.ssh sudo touch /home/deploy/.ssh/authorized_keys sudo chmod 700 /home/deploy/.ssh sudo chmod 644 /home/deploy/.ssh/authorized_keys sudo chown -R deploy:deploy /home/deploy As root on the target server:\n1 sudo vim /etc/ssh/sshd_config Verify that password authentication is set to “no”:\n1 PasswordAuthentication no Add deploy to sudoers Finally we\u0026rsquo;ll add the user to sudo.\nAs root on the target machine:\n1 visudo This will open the sudoers file where we can add the deploy users privileges below root like this:\n1 2 3 4 5 # User privilege specification root ALL=(ALL:ALL) ALL deploy ALL=(ALL) NOPASSWD: ALL Add ssh public key to authorized_keys In another terminal window, on your local machine:\n1 cat ~/.ssh/id_rsa.pub On the target server, paste the key into authorized_keys:\n1 sudo vim /home/deploy/.ssh/authorized_keys Now we can safely log in and work as the deploy user on the target machine without having to enter a password.\nNow go to Basic Hardening article to remove root login.\nSet up your firewall on Ubuntu source/credit: https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04\nUbuntu 18.04 servers can use the UFW firewall to make sure only connections to certain services are allowed. We can set up a basic firewall very easily using this application.\nDifferent applications can register their profiles with UFW upon installation. These profiles allow UFW to manage these applications by name. OpenSSH, the service allowing us to connect to our server now, has a profile registered with UFW.\nYou can see this by typing:\n1 ufw app list Output:\n1 2 Available applications: OpenSSH We need to make sure that the firewall allows SSH connections so that we can log back in next time. We can allow these connections by typing:\n1 ufw allow OpenSSH Afterwards, we can enable the firewall by typing:\n1 ufw enable Type “y” and press ENTER to proceed. You can see that SSH connections are still allowed by typing:\n1 ufw status Output:\n1 2 3 4 5 6 Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) As the firewall is currently blocking all connections except for SSH, if you install and configure additional services, you will need to adjust the firewall settings to allow acceptable traffic in. You can learn some common UFW operations in this guide.\nStep 3: Target Server - Install asdf Sometimes, you’ll need to install specific versions or Erlang, Elixir or Node, and we’ll use asdf, a version manager to tackle this complex task.\nasdf is an extendable version manager with support for Ruby, Node.js, Elixir, Erlang \u0026amp; more.\nTo install it, we’ll first switch over to our newly created deploy user.\nOn the target server as root:\n1 2 $ su deploy $ cd # move into deploy\u0026#39;s home path Install asdf Install dependencies:\n1 2 3 4 5 6 7 8 9 10 11 12 13 sudo add-apt-repository \u0026#34;deb http://archive.ubuntu.com/ubuntu $(lsb_release -sc) main universe restricted multiverse\u0026#34; sudo add-apt-repository \u0026#34;deb http://archive.ubuntu.com/ubuntu $(lsb_release -sc) universe\u0026#34; sudo apt-get update sudo apt-get install -y build-essential git wget libssl-dev libreadline-dev \\ libncurses5-dev zlib1g-dev m4 curl wx-common libwxgtk3.0-dev autoconf \\ libxml2-utils xsltproc fop unixodbc unixodbc-bin unixodbc-dev sudo apt-get install openjdk-8-jdk sudo apt-get autoremove sudo apt-get upgrade Ensure that you are using the deploy account, and clone the repo:\n1 git clone https://github.com/asdf-vm/asdf.git ~/.asdf After this you need to add asdf to your deploy user bash profile:\n1 2 cd ~ vim ~/.profile Add this at the end of your profile:\n1 . $HOME/.asdf/asdf.sh Optional step if you are on $5 Digital Ocean Droplet For $5 droplet, asdf only works if you create a swapspace (I set it to 4GB) and wait a bit for asdf to install and build erlang felt like 30 min. See solution: (https://www.digitalocean.com/community/tutorials/how-to-add-swap-space-on-ubuntu-18-04) See the problem reported: (https://github.com/asdf-vm/asdf-erlang/issues/91)\nSwitch to root to create swap space.\nWe can see if the system has any configured swap by typing:\n1 sudo swapon --show You can verify that there is no active swap using the free utility:\n1 free -h Create swap file. The size of swap file is usually double your ram. But do 4G minimum.\n1 sudo fallocate -l 4G /swapfile We can verify that the correct amount of space was reserved by typing:\n1 ls -lh /swapfile Enabling the swap file Now that we have a file of the correct size available, we need to actually turn this into swap space.\nFirst, we need to lock down the permissions of the file so that only the users with root privileges can read the contents. This prevents normal users from being able to access the file, which would have significant security implications.\nMake the file only accessible to root by typing:\n1 sudo chmod 600 /swapfile Verify the permissions change by typing:\n1 ls -lh /swapfile As you can see, only the root user has the read and write flags enabled.\nWe can now mark the file as swap space by typing:\n1 sudo mkswap /swapfile Output:\n1 2 Setting up swapspace version 1, size = 1024 MiB (1073737728 bytes) no label, UUID=6e965805-2ab9-450f-aed6-577e74089dbf After marking the file, we can enable the swap file, allowing our system to start utilizing it:\n1 sudo swapon /swapfile Verify that the swap is available by typing:\n1 sudo swapon --show Making the swapfile permanent Our recent changes have enabled the swap file for the current session. However, if we reboot, the server will not retain the swap settings automatically. We can change this by adding the swap file to our /etc/fstab file.\nBack up the /etc/fstab file in case anything goes wrong:\n1 sudo cp /etc/fstab /etc/fstab.bak Add the swap file information to the end of your /etc/fstab file by typing:\n1 echo \u0026#39;/swapfile none swap sw 0 0\u0026#39; | sudo tee -a /etc/fstab Now switch to deploy user and check to see if asdf by typing asdf.\nStep 4: Target Server - Install Erlang/Elixir Because we need our Phoenix project to run on both the local development machine and the production server, we’ll need to install the same languages and tools in both places. Erlang 21.1, and Elixir 1.7.4.\nInstall Erlang We’re going to use asdf to install Erlang. I uses plugins for different libraries, so let’s add the plugin:\nAs deploy on the target machine:\n1 asdf plugin-add erlang Install Erlang/OTP 22 (or whichever version your app needs)\n1 2 asdf install erlang 22.0 asdf global erlang 22.0 OPTIONAL If anything went wrong or if dependencies skipped\n1 2 3 4 asdf plugin-remove erlang asdf plugin-remove elixir asdf plugin-add erlang asdf plugin-add elixir Install Elixir As deploy add the plugin:\n1 asdf plugin-add elixir Install Elixir and make it global:\n1 2 asdf install elixir 1.8.2 asdf global elixir 1.8.2 Now you can open a new terminal and try erl:\n1 erl And you can try iex:\n1 iex Use asdf .tool-versions file to manage which version is active on each of your projects.\nUse Mix to install Hex.\n1 mix local.hex Step 5: Target Server - Install Nodejs Installing Node is straightforward with a few commands.\nNOTE: Look up what NODE version to install. Replace XX with version number such as 12. see https://github.com/nodesource/distributions/blob/master/README.md\n1 2 3 sudo apt install curl curl -sL https://deb.nodesource.com/setup_XX.x | sudo -E bash - sudo apt-get install -y nodejs Step 6: Target Server - Install Postgresql base on https://computingforgeeks.com/install-postgresql-11-on-ubuntu-18-04-ubuntu-16-04/\nAs root on the target server:\nAdd PostgreSQL 11 APT repository (for Bionic 18.04 ubuntu)\nhttps://www.postgresql.org/download/linux/ubuntu/\nCreate the file /etc/apt/sources.list.d/pgdg list and add a line for the repository.\n1 sudo vim /etc/apt/sources.list.d/pgdg.list Add this line:\n1 deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main Import the repository signing key, and update the package lists :\n1 2 wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - sudo apt-get update Install PostgreSQL 11 on Ubuntu 18.04 / Ubuntu 16.04 After importing GPG key, add repository contents to your Ubuntu 18.04/16.04 system:\n1 sudo apt-get install postgresql-11 Verify repository file contents\n1 cat /etc/apt/sources.list.d/pgdg.list Create new database user During the postgres installation, a postgres root user postgres was created, but we don’t want to connect to the server with this user. Let’s create a separate postgres user for our app.\nYou can switch to the postgres user with su postgres than back to root with exit\nOn the target server, switch to the postgres user, create a phx database user and set the new user’s password:\n1 2 3 4 5 6 $ su postgres $ cd ~ $ createuser phx --pwprompt Enter password for new role: Enter it again: NOTE: Remember these credentials as they’ll be used once we configure our Phoenix application for production.\nCreate production database: We’ll need to create our production database manually as edeliver only manages migrations.\nAs postgres on the target server:\n1 createdb fumigate_prod Then log in to psql:\n1 psql Ensure that you are logged into the postgres cli tool and run:\n1 GRANT ALL PRIVILEGES ON DATABASE fumigate_prod TO phx; This gives our new phx user access to the newly created database. Exit psql with \\q.\nDatabase credentials: To re-cap:\nusername: phx password: \u0026lt;yourpass\u0026gt; database: fumigate_prod Step 7: Target Server - Production Configuration Create prod.secret.exs You may have noticed that Phoenix created a config/prod.secret.exs file. This is imported by config/prod.exs but is ignored by git by default. We’ll need to create this file on the target machine so edeliver can symlink to it during the build process.\nWe’re also going to store our applications in ~/apps/\u0026lt;appname\u0026gt; format which is the equivalent of /home/deploy/apps/\u0026lt;appname\u0026gt;.\nLet’s switch over to our deploy user. On the target machine:\n1 2 su deploy cd Make a new directory for our secrets:\n1 mkdir -p apps/fumigate/secret Then create a new prod.secret.exs file in that directory:\n1 vim ~/apps/fumigate/secret/prod.secret.exs Add this content to it:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 use Mix.Config config :fumigate, FumigateWeb.Endpoint, secret_key_base: \u0026#34;YOURKEYHERE+v7fAdFNvoSZpUwTU96jA0UjEF1sgiVwdI5F\u0026#34; config :fumigate, Fumigate.Repo, username: \u0026#34;phx\u0026#34;, password: \u0026#34;yourpassword\u0026#34;, database: \u0026#34;fumigate_prod\u0026#34;, pool_size: 15 You can generate a new secret key by using mix phx.gen.secret on your local machine.\nIMPORTANT: Update the file to have a production ready secret key, and the database credentials you set from earlier.\nStep 8: Install Distillery and edeliver As previously mentioned, Distillery compiles our Phoenix application into releases, and edeliver uses ssh and scp to build and deploy the releases to our production server.\nOn your local machine, open mix.exs and add 2 deps:\n1 2 {:edeliver, \u0026#34;\u0026gt;= 1.6.0\u0026#34;}, {:distillery, \u0026#34;~\u0026gt; 2.0\u0026#34;, warn_missing: false}, And add :edeliver to extra_applications in the application block:\n1 2 3 4 5 6 def application do [ mod: {Fumigate.Application, []}, extra_applications: [:logger, :runtime_tools, :edeliver] ] end Use mix to install deps:\n1 mix deps.get Initialize Distillery Distillery requires a build configuration file that is not generated by default.\nLet’s generate it with:\n1 mix distillery.init This generates configuration files for Distillery in the rel directory. We don’t need to make any changes to the default config.\nWe now need to exclude .deliver/releases/ from our git repo.\n1 echo \u0026#34;.deliver/releases/\u0026#34; \u0026gt;\u0026gt; .gitignore Configure edeliver Create a .deliver directory in your project folder and add the config file: (Change the IP to your server IP 134.209.8.141)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #!/bin/bash APP=\u0026#34;fumigate\u0026#34; BUILD_HOST=\u0026#34;134.209.8.141\u0026#34; BUILD_USER=\u0026#34;deploy\u0026#34; BUILD_AT=\u0026#34;/tmp/edeliver/$APP/builds\u0026#34; START_DEPLOY=true CLEAN_DEPLOY=true # prevent re-installing node modules; this defaults to \u0026#34;.\u0026#34; GIT_CLEAN_PATHS=\u0026#34;_build rel priv/static\u0026#34; PRODUCTION_HOSTS=\u0026#34;134.209.8.141\u0026#34; PRODUCTION_USER=\u0026#34;deploy\u0026#34; DELIVER_TO=\u0026#34;/home/deploy/apps\u0026#34; # For Phoenix projects, symlink prod.secret.exs to our tmp source pre_erlang_get_and_update_deps() { local _prod_secret_path=\u0026#34;/home/deploy/apps/$APP/secret/prod.secret.exs\u0026#34; if [ \u0026#34;$TARGET_MIX_ENV\u0026#34; = \u0026#34;prod\u0026#34; ]; then status \u0026#34;Linking \u0026#39;$_prod_secret_path\u0026#39;\u0026#34; __sync_remote \u0026#34; [ -f ~/.profile ] \u0026amp;\u0026amp; source ~/.profile mkdir -p \u0026#39;$BUILD_AT\u0026#39; ln -sfn \u0026#39;$_prod_secret_path\u0026#39; \u0026#39;$BUILD_AT/config/prod.secret.exs\u0026#39; \u0026#34; fi } pre_erlang_clean_compile() { status \u0026#34;Running npm install\u0026#34; __sync_remote \u0026#34; [ -f ~/.profile ] \u0026amp;\u0026amp; source ~/.profile set -e cd \u0026#39;$BUILD_AT\u0026#39;/assets npm install \u0026#34; status \u0026#34;Compiling assets\u0026#34; __sync_remote \u0026#34; [ -f ~/.profile ] \u0026amp;\u0026amp; source ~/.profile set -e cd \u0026#39;$BUILD_AT\u0026#39;/assets node_modules/.bin/webpack --mode production --silent \u0026#34; status \u0026#34;Running phoenix.digest\u0026#34; # log output prepended with \u0026#34;-----\u0026gt;\u0026#34; __sync_remote \u0026#34; # runs the commands on the build host [ -f ~/.profile ] \u0026amp;\u0026amp; source ~/.profile # load profile (optional) set -e # fail if any command fails (recommended) cd \u0026#39;$BUILD_AT\u0026#39; # enter the build directory on the build host (required) # prepare something mkdir -p priv/static # required by the phoenix.digest task # run your custom task APP=\u0026#39;$APP\u0026#39; MIX_ENV=\u0026#39;$TARGET_MIX_ENV\u0026#39; $MIX_CMD phx.digest $SILENCE APP=\u0026#39;$APP\u0026#39; MIX_ENV=\u0026#39;$TARGET_MIX_ENV\u0026#39; $MIX_CMD phx.digest.clean $SILENCE \u0026#34; } These are mostly environment variables use by Edeliver in the shell scripts. Go through them one by one and try to understand what they’re doing.\nYou can read more about the configuration variables in their Wiki.\nDon’t forget to update your host configuration\nThe custom functions are hooks that run during different phases of the deployment.\nYou can also read more about running additional tasks in their Wiki.\nProject prod configuration We’ll need to make some changes to the default production configuration in our project.\nDO NOT RUN ON PORT 80. KEEP IT AT 4000. The application is running on deploy there fore it cannot run on port 80. We need to route incoming requests from 80 http and https to port 4000. Do not attempt to run app as root. That’s asking for trouble. Source: https://elixirforum.com/t/running-on-ec2-giving-error/13574/5\nOpen config/prod.exs and update it to this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 use Mix.Config config :fumigate, FumigateWeb.Endpoint, http: [:inet6, port: System.get_env(\u0026#34;PORT\u0026#34;) || 4000], url: [host: \u0026#34;fumigatedb.com\u0026#34;, port: 80], cache_static_manifest: \u0026#34;priv/static/cache_manifest.json\u0026#34;, server: true, code_reloader: false # Do not print debug messages in production config :logger, level: :info # ## SSL Support # # To get SSL working, you will need to add the `https` key # to the previous section and set your `:url` port to 443: # # config :fumigate, FumigateWeb.Endpoint, # ... # url: [host: \u0026#34;example.com\u0026#34;, port: 443], # https: [ # :inet6, # port: 443, # cipher_suite: :strong, # keyfile: System.get_env(\u0026#34;SOME_APP_SSL_KEY_PATH\u0026#34;), # certfile: System.get_env(\u0026#34;SOME_APP_SSL_CERT_PATH\u0026#34;) # ] # # The `cipher_suite` is set to `:strong` to support only the # latest and more secure SSL ciphers. This means old browsers # and clients may not be supported. You can set it to # `:compatible` for wider support. # # `:keyfile` and `:certfile` expect an absolute path to the key # and cert in disk or a relative path inside priv, for example # \u0026#34;priv/ssl/server.key\u0026#34;. For all supported SSL configuration # options, see https://hexdocs.pm/plug/Plug.SSL.html#configure/1 # # We also recommend setting `force_ssl` in your endpoint, ensuring # no data is ever sent via http, always redirecting to https: # # config :fumigate, FumigateWeb.Endpoint, # force_ssl: [hsts: true] # # Check `Plug.SSL` for all available options in `force_ssl`. # ## Using releases (distillery) # # If you are doing OTP releases, you need to instruct Phoenix # to start the server for all endpoints: # config :phoenix, :serve_endpoints, true # # Alternatively, you can configure exactly which server to # start per endpoint: # # config :fumigate, FumigateWeb.Endpoint, server: true # # Note you can\u0026#39;t rely on `System.get_env/1` when using releases. # See the releases documentation accordingly. # Finally import the config/prod.secret.exs which should be versioned # separately. import_config \u0026#34;prod.secret.exs\u0026#34; These are settings recommended by Distillery. You might notice that we’re setting the system port using the PORT environment variable. This needs to be available during the build process and we can add it to the ~/.profile file on our production server.\nAdd env Variables to Target Server Login as deploy to the target server.\nOpen up the .profile.\n1 2 cd ~ vim ~/.profile And add these lines:\n1 2 export MIX_ENV=prod export PORT=4000 This will ensure that our system runs on port 4000, and that the environment is set to prod.\nLogout of deploy and log back in for ~/.profile be in effect.\nStep 9: Deployment We’re finally ready to build and deploy our first release. The default version is 0.1.0 so let’s just keep that for now.\nWarning: the commands for building and deploy can seem complicated at first but once you become familiar with them, you will see that they use a natural language style.\nBuild the production release: NOTE: edeliver uses git master branch to build the code into release package.\nIn your project directory and git master branch:\n1 mix edeliver build release production --verbose This builds the release on the target server, and stores the archive in your local .edeliver/releases directory.\nDeploy the reload to production: In your project directory:\n1 2 3 mix edeliver deploy release to production --verbose mix edeliver migrate production --verbose mix edeliver start production --verbose Other neat edeliver commands:\n1 2 3 4 5 mix edeliver ping production # shows which nodes are up and running mix edeliver version production # shows the release version running on the nodes mix edeliver show migrations on production # shows pending database migrations mix edeliver migrate production # run database migrations mix edeliver restart production # or start or stop You can read more about Edeliver in their documentation.\nView our website on our server 1 2 ssh deploy@188.166.182.170 curl localhost:4000 Step 10: Generating SSL CERT - BEFORE Routing incoming http request to port 4000 (our phoenix app) https://www.digitalocean.com/community/tutorials/how-to-use-certbot-standalone-mode-to-retrieve-let-s-encrypt-ssl-certificates-on-ubuntu-1804\nhttps://github.com/certbot/certbot/issues/5257\nWe should generate SSL Certificate. The certbot generator needs port 80. So you need to do this before rerouting incoming port 80 requests to our phoenix web app that’s listening on port 4000.\nStep 1 — Installing Certbot The first step to using Let’s Encrypt to obtain an SSL certificate is to install the Certbot software on your server.\nCertbot is in very active development, so the Certbot packages provided by Ubuntu tend to be outdated. However, the Certbot developers maintain a Ubuntu software repository with up-to-date versions, so we’ll use that repository instead.\nFirst, add the repository:\n1 2 sudo add-apt-repository ppa:certbot/certbot apt-get update Install certbot:\n1 sudo apt-get install certbot Step 2 — Generating Certificate Make sure that your firewall is accepting port 80.\n1 sudo ufw allow 80 Generate the SSL cert:\n1 sudo certbot certonly --standalone --preferred-challenges http -d fumigatedb.com -d www.fumigatedb.com Enable it so deploy user and app own by deploy can read those certs:\n1 2 chmod 755 /etc/letsencrypt/live/ chmod 755 /etc/letsencrypt/archive/ We’ll get back to using cert on the server soon in step 13.\nStep 11: Routing incoming http request to port 4000 (our phoenix app) https://serverfault.com/questions/238563/can-i-use-ufw-to-setup-a-port-forward\nLet’s say you want to forward requests going to 80 (http) to a server listening on port 4000.\nNote that you will need to make sure port 8080 is allowed, otherwise ufw will block the requests that are redirected to 4000.\n1 sudo ufw allow 4000/tcp There are no ufw commands for setting up the port forwards, so it must be done via configuraton files. Add the lines below to /etc/ufw/before.rules, before the filter section, right at the top of the file:\n1 sudo vim /etc/ufw/before.rules 1 2 3 4 *nat :PREROUTING ACCEPT [0:0] -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 4000 COMMIT Then restart the server:\n1 2 sudo reboot ssh deploy@134.209.8.141 Enable ufw to start on boot:\n1 sudo ufw enable Debug tips: check /var/log/syslog\nStep 12: Fail2ban https://www.lifewire.com/harden-ubuntu-server-security-4178243\nhttps://www.techrepublic.com/article/how-to-install-fail2ban-on-ubuntu-server-18-04/\nThe fail2ban system is an intrusion prevention system that monitors log files and searches for particular patterns that correspond to a failed login attempt. If a certain number of failed logins are detected from a specific IP address (within a specified amount of time), fail2ban will block access from that IP address.\nTo install fail2ban, open a terminal window and issue the command:\n1 2 3 sudo apt-get update sudo apt-get upgrade sudo apt-get install -y fail2ban Within the directory /etc/fail2ban, you’ll find the main configuration file, jail.conf. Also in that directory is the subdirectory, jail.d. The jail.conf file is the main configuration file and jail.d contains the secondary configuration files. Do not edit the jail.conf file. Instead, we’ll create a new configuration that will monitor SSH logins with the command:\n1 sudo vim /etc/fail2ban/jail.local In this new file add the following contents:\n1 2 3 4 5 6 [sshd] enabled = true port = 22 filter = sshd logpath = /var/log/auth.log maxretry = 3 This configuration does the following:\nEnables the jail. Sets the SSH port to be monitored to 22. Uses the sshd filter. Sets the log file to be monitored. Save and close that file. Restart fail2ban with the command:\n1 2 3 sudo systemctl start fail2ban sudo systemctl enable fail2ban sudo systemctl restart fail2ban If you attempt to Secure Shell into that server and fail the log in three times (set as the default by fail2ban), access will be then blocked from the IP address you are working from.\nTesting and unbanning You can test to make sure the new jail works by failing three attempts at logging into the server, via ssh. After the third failed attempt, the connection will hang. Hit [Ctrl]+[c] to escape and then attempt to SSH back into the server. You should no longer be able to SSH into that server from the IP address you were using.\nYou can then unban your test IP address with the following command:\n1 sudo fail2ban-client set sshd unbanip IP_ADDRESS where IP_ADDRESS is the banned IP Address.\nYou should now be able to log back into the server with SSH.\nScratching the surface This barely scratches the surface as to what fail2ban can do. But now you have a good idea on how to use the system. To find out more, make sure to read the man page with the command:\n1 man fail2ban That manual page provides a good overview of what fail2ban can do.\nStep 13: Port foward SSL to Port 4001 Set up the firewall:\n1 2 3 sudo ufw allow https sudo ufw allow 443 sudo ufw allow 4001 There are no ufw commands for setting up the port forwards, so it must be done via configuraton files. Add the lines below to /etc/ufw/before.rules, before the filter section, right at the top of the file:\n1 sudo vim /etc/ufw/before.rules 1 2 3 4 *nat :PREROUTING ACCEPT [0:0] -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 4001 COMMIT Then restart the server:\n1 2 3 sudo ufw enable sudo reboot ssh deploy@134.209.8.141 Step 14: SSL https://blog.progressplum.app/ssl-migration-from-nginx-to-cowboy-2-in-phoenix-1-4/\nhttps://medium.com/@zek/secure-your-phoenix-app-with-free-ssl-48ac749c17d7\nStep 1 — Generating Diffie Hellman parameters If you don’t already have a set of Diffie Hellman parameters[2] to use with your SSL, generate a new set for extra security. Run this command on the server but be aware that it’s very CPU-intensive and may take a while on a slow VPS.\n1 openssl dhparam -out /etc/letsencrypt/dhparam.pem 4096 Step 2 — Set up your environment 1 sudo vim ~/.profile 1 2 3 4 5 6 7 8 9 10 11 12 13 export MIX_ENV=prod export PORT=4000 export SPORT=4001 export SSL_CERT_FILE=/etc/letsencrypt/live/fumigatedb.com/cert.pem export SSL_CACERT_FILE=/etc/letsencrypt/live/fumigatedb.com/chain.pem export SSL_KEY_FILE=/etc/letsencrypt/live/fumigatedb.com/privkey.pem export SSL_DHPARAM_FILE=/etc/letsencrypt/dhparam.pem Change fumigatedb.com to your domainname.\nStep 3 — prod Configuration Update your application’s Endpoint configuration to add SSL support in config/prod.exs.\n1 vim config/prod.exs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 config :fumigate, FumigateWeb.Endpoint, url: [scheme: \u0026#34;https\u0026#34;, host: \u0026#34;fumigatedb.com\u0026#34;, port: 443], http: [:inet6, port: System.get_env(\u0026#34;PORT\u0026#34;) || 4000], https: [ :inet6, port: System.get\\_env(\u0026#34;SPORT\u0026#34;) || 4001, otp_app: :fumigate, cipher_suite: :strong, keyfile: System.get_env(\u0026#34;SSL_KEY_FILE\u0026#34;), certfile: System.get_env(\u0026#34;SSL_CERT_FILE\u0026#34;), cacertfile: System.get_env(\u0026#34;SSL_CACERT_FILE\u0026#34;), dhfile: System.get_env(\u0026#34;SSL_DHPARAM_FILE\u0026#34;) ], cache_static_manifest: \u0026#34;priv/static/cache_manifest.json\u0026#34;, server: true, code_reloader: false Save to git master repo and rerun edeliver again.\n1 2 3 4 5 6 git commit -a -m \u0026#34;edited prod.exs to add HTTPS scheme\u0026#34; git push origin master mix edeliver build release production --verbose mix edeliver deploy release to production mix edeliver stop production mix edeliver start production Check the ssl website now with: https://www.ssllabs.com/ssltest/\nStep 4 — Application Configuration forcing SSL 1 2 3 4 5 6 7 8 9 10 11 git commit -a -m \u0026#34;edited prod.exs to force SSL connection\u0026#34; git push origin master mix edeliver build release production --verbose mix edeliver deploy release to production mix edeliver stop production mix edeliver start production Step 5 — Increasing the security of SSL https://elixirforum.com/t/making-ssl-tests-all-pass-for-phoenix-lets-encrypt/3507/11\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 use Mix.Config # For production, don\u0026#39;t forget to configure the url host # to something meaningful, Phoenix uses this information # when generating URLs. # # Note we also include the path to a cache manifest # containing the digested version of static files. This # manifest is generated by the `mix phx.digest` task, # which you should run after static files are built and # before starting your production server. config :fumigate, FumigateWeb.Endpoint, url: [scheme: \u0026#34;https\u0026#34;, host: \u0026#34;fumigatedb.com\u0026#34;, port: 443], force_ssl: [hsts: true], http: [:inet6, port: System.get_env(\u0026#34;PORT\u0026#34;) || 4000], https: [ :inet6, port: System.get_env(\u0026#34;SPORT\u0026#34;) || 4001, otp_app: :fumigate, cipher_suite: :strong, keyfile: System.get_env(\u0026#34;SSL_KEY_FILE\u0026#34;), certfile: System.get_env(\u0026#34;SSL_CERT_FILE\u0026#34;), cacertfile: System.get_env(\u0026#34;SSL_CACERT_FILE\u0026#34;), dhfile: System.get_env(\u0026#34;SSL_DHPARAM_FILE\u0026#34;), versions: [:\u0026#34;tlsv1.2\u0026#34;, :\u0026#34;tlsv1.1\u0026#34;, :\u0026#34;tlsv1\u0026#34;], ciphers: ~w( ECDHE-ECDSA-AES256-GCM-SHA384 ECDHE-ECDSA-AES256-SHA384 ECDHE-ECDSA-AES128-GCM-SHA256 ECDHE-ECDSA-AES128-SHA256 ECDHE-ECDSA-AES256-SHA ECDHE-ECDSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES256-SHA ECDHE-RSA-AES128-SHA ECDH-ECDSA-AES256-GCM-SHA384 ECDH-ECDSA-AES256-SHA384 ECDH-ECDSA-AES128-GCM-SHA256 ECDH-ECDSA-AES128-SHA256 DHE-RSA-AES256-GCM-SHA384 DHE-RSA-AES256-SHA256 DHE-DSS-AES256-GCM-SHA384 DHE-DSS-AES256-SHA256 DHE-RSA-AES256-SHA DHE-DSS-AES256-SHA DHE-DSS-AES128-GCM-SHA256 DHE-RSA-AES128-GCM-SHA256 DHE-RSA-AES128-SHA256 DHE-DSS-AES128-SHA256 DHE-RSA-AES128-SHA DHE-DSS-AES128-SHA AES128-GCM-SHA256 AES128-SHA DES-CBC3-SHA )c, secure_renegotiate: true, reuse_sessions: true, honor_cipher_order: true, client_renegotiation: false, eccs: [ :sect571r1, :sect571k1, :secp521r1, :brainpoolP512r1, :sect409k1, :sect409r1, :brainpoolP384r1, :secp384r1, :sect283k1, :sect283r1, :brainpoolP256r1, :secp256k1, :secp256r1, :sect239k1, :sect233k1, :sect233r1, :secp224k1, :secp224r1 ], ], cache_static_manifest: \u0026#34;priv/static/cache_manifest.json\u0026#34;, server: true, code_reloader: false # Do not print debug messages in production config :logger, level: :info # ## SSL Support # # To get SSL working, you will need to add the `https` key # to the previous section and set your `:url` port to 443: # # config :fumigate, FumigateWeb.Endpoint, # ... # url: [host: \u0026#34;example.com\u0026#34;, port: 443], # https: [ # :inet6, # port: 443, # cipher_suite: :strong, # keyfile: System.get_env(\u0026#34;SOME_APP_SSL_KEY_PATH\u0026#34;), # certfile: System.get_env(\u0026#34;SOME_APP_SSL_CERT_PATH\u0026#34;) # ] # # The `cipher_suite` is set to `:strong` to support only the # latest and more secure SSL ciphers. This means old browsers # and clients may not be supported. You can set it to # `:compatible` for wider support. # # `:keyfile` and `:certfile` expect an absolute path to the key # and cert in disk or a relative path inside priv, for example # \u0026#34;priv/ssl/server.key\u0026#34;. For all supported SSL configuration # options, see https://hexdocs.pm/plug/Plug.SSL.html#configure/1 # # We also recommend setting `force_ssl` in your endpoint, ensuring # no data is ever sent via http, always redirecting to https: # # # Check `Plug.SSL` for all available options in `force_ssl`. # ## Using releases (distillery) # # If you are doing OTP releases, you need to instruct Phoenix # to start the server for all endpoints: # config :phoenix, :serve_endpoints, true # # Alternatively, you can configure exactly which server to # start per endpoint: # # config :fumigate, FumigateWeb.Endpoint, server: true # # Note you can\u0026#39;t rely on `System.get_env/1` when using releases. # See the releases documentation accordingly. # Finally import the config/prod.secret.exs which should be versioned # separately. import_config \u0026#34;prod.secret.exs\u0026#34; Credit Base on these resources: https://devato.com/automate-elixir-phoenix-1-4-deployment-with-distillery-and-edeliver-on-ubuntu/#step-6-target-server-install-nodejs https://medium.com/@zek/deploy-early-and-often-deploying-phoenix-with-edeliver-and-distillery-part-one-5e91cac8d4bd https://medium.com/@zek/deploy-early-and-often-deploying-phoenix-with-edeliver-and-distillery-part-two-f361ef36aa10 https://blog.progressplum.app/ssl-migration-from-nginx-to-cowboy-2-in-phoenix-1-4/ https://elixirforum.com/t/elixir-1-9-releases-with-edeliver/23728/3?u=mythicalprogrammer Pictures First picture: Color Phoenix Tradition ","date":"2019-09-16T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/elixir-phoenix-deploy-distillery-and-edeliver/color-1544543_1280_hu03f7c0de7591ec620ffda9d2135553d8_169172_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/elixir-phoenix-deploy-distillery-and-edeliver/","title":"Elixir Phoenix 1.4 Deployments with Distillery and Edeliver on Ubuntu"},{"content":"Books I’ve read this week So I’m reading up my tech stack I’ve chosen for the next five years for my start up. Mostly setting up my dev machine and foundation toolings.\nAbsolute OpenBSD Unix for the Practical Paranoid (2nd Edition) by Michael W. Lucas\nThe partition harddrive during installing of this book is outdated.\nTutorial I’ve used is:\nhttps://sohcahtoa.org.uk/openbsd.html https://www.c0ffee.net/blog/openbsd-on-a-laptop/ I’ve installed xfce window manager desktop whatever and there were some hiccup. Especially having to figure out to enable an option for xfce terminal to run as shell login user (why is this not default?).\nI’ve also set up ksh terminal using polyglot github configuration. It works for me.\ntmux 2 Productive Mouse-Free Development by Brian P. Hogan\nI’ve read this book a few years ago and it’s the reason why I am good at tmux. I learned about tmux at a Ruby on Rail talk 10 years ago.\nI’m using this config file with a few tweaks. The pane split short cut for both horizontal and vertical are the same \u0026gt;___\u0026gt;. Also copy mode doesn’t use vi key even though pane navigation uses vi keys.\nI couldn’t get the font working on OpenBSD and am still working on it. It’s in the backburner.\nWhat am I reading next In the technology queue there are two books.\nI would like the latest Vim book. I’ve read the practical vim book and currently want to read up on neo vim and the latest book by the same author iirc. https://pragprog.com/book/modvim/modern-vim\nThe vim one will be handy since R studio is not a port in OpenBSD and the dependancies is pretty bad to make it port.\nI’ve found this sweeet article from my alma mata for vim+tmux R dev: https://hpcc.ucr.edu/manuals_linux-cluster_terminalIDE.html\nAlso forgot about this one: https://kadekillary.work/post/nvim-r/\nAlso a sweet website for top vim plugins: vim awesome\nAnother one I would like to read is a postgresql book. I’ll start with the book below and see how it goes.\nLearning PostgreSQL 10 - Second Edition by Andrey Volkov and Salahaldin Juba\nThere’s also a pretty interesting one in depth: Use the Index Luke\nFrom there I have an elixir book to read and a phoenix book but that’s for later.\nRandom thoughts on publishers It seems like I’m moving away from manning and have been reading a lot of Pragmatic Programmers and No Stach publisher.\nPackt is really a hit or miss.\nWhat about books in other subject? I’m reading a few self help books, which is personal, so I won’t be putting it here. Just trying to be my best self that’s all.\nAs for statistic, I’ve found a new spatial modeling book that was recently released: Geocomputation with R by Robin Lovelace, Jakub Nowosad, Jannes Muenchow\nI dislike the title name because it sounds funky to be honest I’m hoping it spatial analysis which from the summary it is. Maybe geocomputation is some domain specific terminology I don’t know and I’m just being silly.\nFeel free to hit me up on twitter, mastodon, and whatever if you guys have any suggestions on books either technical or self help or statistical modeling.\nHave a wonderful week.\nCredits First picture: https://pixabay.com/en/books-door-entrance-culture-1655783/ Second picture: https://pixabay.com/en/narrative-history-dream-tell-794978/ Third picture: https://pixabay.com/en/sunset-island-mar-dusk-brain-485016/ ","date":"2018-12-16T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/books-i-ve-read-this-week-and-future-reading-plans/books-1655783_1280_huf9341335e8f72240952417d2ba534169_608015_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/books-i-ve-read-this-week-and-future-reading-plans/","title":"Books I've read this week and future reading plans."},{"content":"Introduction This week I had to study for a job interview at a pretty sweet place. So in preparation for it I’ve read up on statistics that I’ve listed on my resume. I’ve came across a few good papers and I’m just happy to have read it. Just wanted to post it here in case if I ever need a refresher on Bayesian.\nBasic Master Level Statistic Introductory Mathematical Statistics Methods of Estimation and Properties of Point Estimators: Fundamental Exercises with Solutions by Dr. Olga Korosteleva\nThis is written by my professor and it was in a neat package of overview of what I’ve learned in my master program. It is a good refresher. There were some notes I’ve written for clarifications:\nMLE - This selects the parameter values that make the data most probable\rLikelihood (frequentist point of view) - is a function of the parameters of a statistical model, given specific observed data.\rMethod of Moments Estimators (MOM) \u0026 MLE are two estimator methods to do point estimation for parameter. This is the frequentist point of view on estimating parameters which are fixed. Where as Bayesian model parameter as a random variable and not a fixed point.\rFisher information - is a way of measuring the amount of information that an observable random variable X carries about an unknown parameter theta of a distribution models X.\rCramer-Rao Lower Bound - expresses a lower-bound on the variance of unbiased estimators of a deterministic parameter. An unbiased estimator which achieves this lower bound is efficient.\rSufficient Statistic - a statistic that summarize all of the information in a sample about the desired parameter. (Penn State have more clarification on this).\rBayesian Review On Bayesian Data Analysis by Christian P. Robert and Judith Rousseau (August 27, 2018)\nPoint estimation parameter vs parameter with distribution. Credible Interval vs Confidence Interval. Critiques of Bayesian and solutions.\nAn Introduction to Bayesian Statistics Without Using Equations by Tomoharu Eguchi (2008)\nGreat visualization take on how to explain Bayesian Statistic.\nA tutorial on Bayesian nonparametric models by Samuel J. Gershman and David M. Blei (2012)\nA review what I used during my time at the FDA.\nCredits First picture: https://pixabay.com/en/book-magnifying-glass-glass-2304078/\n","date":"2018-12-13T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/interesting-papers-i-ve-read-this-week/book-2304078_1920_hudbbbaa23eb712c9e80c8b666d23f0fa6_671506_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/interesting-papers-i-ve-read-this-week/","title":"Interesting Papers I've read this week."},{"content":"Introduction I’ve been creating models for a while now.\nRecently read a statistical modeling book on survival analysis and I learned something new. Something that is thought provoking toward modeling.\nI just wanted to put my thoughts on here and see figure out where I’m going with this post when I get there.\nHypothesis, Response type, and Data type I recently have a growth or a better understanding between distinction of research and given data.\nIn the past I believe the data type is what play a role in the class and type of model you can do. Examples of type of model are longitudinal, survival, time series, etc…\nI know as a researcher you have to have a hypothesis first before conducting your experiment and choose your test statistic. If you don’t then you risk introducing bias.\nBut reading a recent book, I’ve come to realize that the hypothesis is the most important thing that dictate your model and the type of data you have at hand is a close second.\nWhat the type of your response in your model dictate your modeling class (longitudinal, survival, etc..). From there you have to make sure your data can address your hypothesis which is tie to the type of your response.\nAgain the hypothesis play a important role to modeling. It then dictate the response type which will dictate what type of data you should have. Then, the data type will dictate what model can you can do.\nBut real life isn’t like this.\nThe majority of data science and machine learning, you have data already. You cannot conduct experiment to generate data yourself because you are given data and expect to work on it. So you essentially skip several step and go straight to what type of data I have at hand and what class of model can I use. If you have a hypothesis it can help but if you have the wrong type of data you cannot answer it.\nBefore I give an example, I want to say most people actually get the data and throw it in a black box algorithm and see what’s going on. Another group of people will look at the data type and see what type of model you can apply. These two cases are mostly for when you are given data and the observations are done already.\nWhen you do research, you get to dictate what you’re looking via hypothesis. Then you get to design the experiment with the type of data you need in mind. Finally the classes of algorithm you can apply is base on your hypothesis and data type.\nBetween the given data and conducting research to get data, I am incline to believe the latter have less chances of bias.\nEtc\u0026hellip; First picture: https://pixabay.com/en/person-reading-studyin-bed-books-984236/\n","date":"2018-11-29T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/things-i-ve-learned-about-modeling/person-984236_1920_hu54856dd37b73ba3ac68393b7b83b222a_651196_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/things-i-ve-learned-about-modeling/","title":"Things I've learned about modeling."},{"content":"Introduction I recently talked to a buddy of mine and we had different view on technology. Being a veteran in the whole gamut full stack of web development I have a set of belief that I’ve come to developed toward technology stack. I didn’t fully express my view when talking to him and I’d like to put it down in words next time I have to discuss such topic.\nThis is also for me to have a clear, rational, and logical argument written down.\nKeeping Up To Date Technology is always changing. There is a new frontend rendering every few months. The people on the otherside will say, “It is up to you to learn and keep up to date.” I used to believe this until the realized this:\nIt sounds great but the fact is when your whole stack change often enough especially when you are a full stack this become a full time job.\nFrontend rendering rate of change is really really fast. That’s great if you don’t have no life, no ambition for relationship or family, etc…\nThe pro to frontend rendering is that we have tons of awesome stuff created by javascript community and I would argue that web component standardization was because of the cuttroat nature of flavor flav of the month frontend rendering javascript.\nI am done with this rat race.\nReason being I have other personal stuff to work on. My goals have changed from making tools for other people, to making tools for me and hoping that other people will find it useful. I’m doing side projects for myself. I get to choose what I feel like reasonable regardless if it’s wrong or not. I’ll learn from my mistakes.\nI am in the current mind set of learning something good and well enough that will survive in at least 2+ years from now.\nKeeping up to date is always something you hear but it’s importance does not overshadow having a reliable technology.\nLet’s start with Database SQL vs NoSQL One statement I made with my buddy is that I’m going to relearn and sharpen my relational database skillset and I’ve chosen PostgreSQL. I’ve been using the ORM libaries of MVC frameworks which abstract from the relation database. This is great but I want to be better and more focus on a piece of technology that I believe in. Plus I’m hoping to learn PostGIS in the future for temporal spatial analysis.\nHe wanted me to use Firebase instead of PostgreSQL.\nI don’t want to do this.\nOne of the biggest reason is that I want to keep my data safe and I want to be in control of my data. The application logic is not the end goal. The real gold, pun intended, is the data. It takes awhile to become an authorative site and developed an active community. The data is what makes this possible. Do not give your data to third party that’s silly.\nAnother reason is that relational database will be here in 10 years from now. I don’t know about anything else but you can try to guess and bet on it. I won’t be taking that bet or joining that rat race.\nI learned and did professionally Cassandra and MongoDB. I don’t know when and where it’ll be in a decade from now. I don’t believe it is a use case for the majority of the data out there, at least the data I care about. I’m not going to write joins manually. How well does my knowledge of column based database structure transferable to other databases? I think SQL is much more transferable than CQL.\nWhen you find yourself doing relational joins and doing nothing with text search in Elasticsearch, Solr, or any Lucene-based database then you’re doing it wrong.\nI can go into B+ trees vs trie but I get paid for that when I did consulting and it’s a huge discussion in itself.\nIt should be the responsibility of the programmer to do a pro and con. Often time than not, those programmers are chasing hype and money. That is fine. I don’t want to be the person getting stuck maintaining such choices when it goes out of vogue. Inheriting technical debt is not fun and if I have the choice then I choose no. Go out there and test those fancy new technology. I’ll wait until they are battle tested, I’ll wait until it’s boring like Ruby on Rails is now.\nThe majority of the data out there are relational. Use a relational database and if you want to gamble try one of the graph database. Also the big data hype is dying down. The majority of the data out there are not big. You don’t need fancy convoluted tech stacks for your small data. If you want to juggle and maintain convoluted tech stacks all day then sure.\nBack to Frontend Rendering Javascript Framework Another technology that keeps on changing is frontend rendering javascript frameworks. I am basically done with this, I went from ember.js, angular.js, and now to Vue.js. I’ll come back when it’s boring. I’ll come back when there are clear winners.\nI’ve highlight the reasons above. Other reason such as the sketchy security issue of npm packages. Or SEO for frontend rendering sucks, it is a bunch of hacks. Supposely Google got something that can handle crawling that. No thanks, I don’t need more headaches. SSR for me.\nI’ve chosen a server side/backend rendering MVC framework, Phoenix and Elixir programming language and call it a day. It’s a small community, the changes aren’t often, and more importantly it’s boring. I am pretty sure it’ll be here at least 2 years from now. It is a bet on my part on this technology but SSR aren’t changing as fast as FSR.\nI also dislike the Node.JS concurrecy model. I prefer Erlang’s actor model. It’s easier to think and debug. I don’t have to do hand threads myself or catch possible error cases. I can just let it crash and only catch cases that I want in Erlang.\nOS As for OS, I’m going for OpenBSD. I want to master an OS and I find that linux is increasingly complicated.\nWhich is fine but I want to know the in’s and out’s of my OS and OpenBSD is boring enough for me. It is small enough for me to figure out all the processes and what the hell is going on.I can tailor it to my developing machine without unnecessary bloat and blobs (heh). OpenBSD also have all the programming languages support I care about (Elixir, NPM,Python, R). I wish it have a better filesystem but I know it’ll work years from now. I’ll wait for Hammer2 and dream about a port over to OpenBSD one day.\nI have stopped doing rat races and refocus on what I care about and this is my new technology stack for my side projects:\nOpenBSD\rPostgreSQL\rPhoenix + Elixir\rThis is my rationality and hopefully there are some wisdoms in these.\nEtc… First picture: https://pixabay.com/en/users/RobinHiggins-1321953\rLast picture: https://pixabay.com/en/grimace-girl-teen-mimicry-brutal-1012862/\r","date":"2018-11-26T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/the-case-for-boring-technology/bored-3082828_1920_hua3f227cc1dad48243028196a49fdfc22_223249_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/the-case-for-boring-technology/","title":"The Case for Boring Technology"},{"content":"Update Busy moving. I have a summer project for this blog (look forward to it, it’ll be fun). I also a summer internship at JPL NASA!\nYou can get the pdf paper here.\nI just finished my semester and I did a final project that I’m pretty proud of. I put in a lot of effort and my professor Dr. Zhou was very awesome.\nAbstract Human immunodeficiency virus or HIV are responsible for decline in CD4+ cell count. The investigation is set out to find the population rate of CD4+ cell count decline per milliliter of blood, to characterize the of individual rate of cell decline, and the factors that predict cell decline. Using exploratory data analysis and longitudinal tools, a linear mixed effects model with random intercept and random slope was created. The estimated population average time course of CD4+ cell depletion is 80.1857 CD4+ cells per milliliter of blood. The degree of heterogeneity across men in the rate of progression as time passes is 54.8061127978 cell count. The factors that predict cell count decline is time, pack of smoke, number of sexual partners, cesd mental illness score, age \u0026amp; time interaction, and smoke \u0026amp; time. The time factor is the most dramatic in term of CD4+ cell depletion.\n1 Introduction 1.1 HIV and CD4+ Cells Human immunodeficiency virus or HIV is a virus that attack immune system by killing a class of immune cell named CD4+ cell. On average a normal person without HIV have 1000 cells per milliliter of blood. As time passes from the initial HIV infection an infected person CD4+ cell counts starts to decline. Acquired immune deficiency syndrome or AIDS is the disease caused by the HIV virus.\n1.2 The Data The data used in this paper is a subset of the Multicenter AIDS Cohort Study with 369 men with HIV. The data consist of columns representing: time since seroconversion, CD4 count, age (relative to arbitrary origin), packs of cigarettes smoked per day, recreational drug use (yes/no), number of sexual partners, CESD (mental illness score), and subject ID. The data have been standardized, the measurements are unbalance, and the time interval are not evenly spaced.\n1.3 Aim of the Investigation The aim of the investigation is four main points: average time course of CD4+ cell depletion, time course for individual men, to characterize the degree of heterogeneity across men in the rate of progression, and factors which predict CD4+ cell changes.\n2 Methods 2.1 Exploratory Data Analysis The goal in exploratory data analysis (EDA) is to have an idea what the CD4+ cell count data looks like and ideas to go from EDA to modeling the data. Creating a response trend model will give an idea how time affect the response and if polynomial time is needed. A variogram graph will indicate what kind of variance is needed to be account for in the model. There are three different kind of variance either random effect variance, within-subject variance, and between-subject variance are needed.\n2.2 Modeling Longitudinal Data The next step is to create a suitable longitudinal model for the CD4+ cell data to answer the aim of this investigation. The model that will be chosen will have to address the variances that was shown in the variogram during EDA. After the model is selected the next step will be predictor selection. The predictor selection will be base on the deviance test of the full and the reduced model. Deviance test will be perform because the comparison are base on nested models.\n2.3 Assumptions The assumptions this investigation made is there are between-subject variations, within-subject variations, and measurement variations that need to be explicitly accounted for. The chosen longitudinal model will account for these explicitly so that the investigation can have an accurate and precise answers to the aim of this investigation.\nBetween-subject is latent factors. Latent factors are biological variability examples are diet, genetics, and other latent factors. Latent factors can keep an individuals CD4+ cell count consistently higher than the population mean or lower than the population mean.\nThe within-subject variation is serial correlation. The serial correlation is induced by time, the close two measurements are the more correlated they are. The farther apart two measurements are the less correlated they are.\nMeasurement variation takes into account for the process of taking measurements is an imperfect process and that there will be some variation in taking CD4+ cell count measurement. A variogram with force equally spacing of time intervals will confirm these assumptions of variations exist in the CD4+ cell count data.\n3 Results 3.1 Exploratory Data Analysis Results Figure 1: A graph between the response of the CD4+ cell count on the y-axis and the time points on the x-axis.\nThe spaghetti plot, Figure 1, shows that the data is unbalanced and that the time intervals are irregular and unequaled. It also show that individual have different base line which imply random intercept and that individual have different rate of progression which imply random slope. This will help in model selection especially when certain covariance structure have assumption about balance data and equally spaced time intervals.\nFigure 2: A graph between the response of the CD4+ cell count on the y-axis and the time points on the x-axis.\nThe response trend graph, Figure 2, indicate that perhaps time is not constant but some sort of polynomial. Between time point 0 and 2 months there is a sharp drop in CD4+ cell count and closer to the 2 month time point the CD4+ cell count rate of decline starts to steady out and the sharp decrease rate is slowed down drastically. Modeling the data with quadratic or cubic time predictor may be needed base on this graph.\nFigure 3: A variogram of the CD4+ cell count data with time intervals forced to be equally space.\nNext is a plotted variogram (Figure 3) to check the assumption of having three sources of variation. Due to the data having unequaled time intervals the measurements are averaged and binned to the nearest time point. The blue line represent that variogram line and the grey horizontal line represents total variance.\nLooking at Figure 3, the variogram blue solid line does not start at zero it indicate that there exist measurement errors. The variogram is not a flat blue line but a slanted line with a slope indicating that there exist serial correlation. Finally the blue line does not touched the upper limit of total variance indicating that there is random effect in play. The assumption that the CD4+ cell count data have all three sources of variation can be safely assume and is verified empirically.\n3.2 Model Selection and Rejected Models Longitudinal analysis have many linear models that to choose from. Models such as unstructured covariance and structured covariance. This section will discuss the reason for not choosing certain models.\nUnstructured covariance is ruled out for two reasons. The first reason being that the large data set and large number of predictors would result in a large amount of parameter estimations. The second reason is that unstructured covariance is unsuitable for data set that have measurement taken at unequally spaced intervals.\nToeplitz covariance structure and autoregressive covariance structure both are other choices of structured covariance model. Both toeplitz and autoregressive assume that measurements are made at equal intervals of time. The CD4+ cell data have irregular unequal intervals of time.\nThe variogram shows there are three sources of variation. Independent model is rejected because the model assume there is only measurement error. Uniform model is also rejected because it only address two sources of variation, measurement error and between-individual variation. Exponential covariance model is rejected because the model address only within-individual variation.\nLinear mixed effects models is chosen is because the model addresses all three sources of variation. The model explicitly distinguished between fixed and random effects. The advantage of this explicit distinction enable accurate and precise answers to the aim of this investigation.\n3.3 Predictor Selection Predictors β_hat values p-values for t-test\rintercept\r790.11\r\u0026lt;.0001\rtime\r-81.6092\r\u0026lt;.0001\rage\r1.6277\r0.3790\rsmoke\r41.0459\r\u0026lt;.0001\rdrug\r22.6537\r0.2677\rpartners\r6.5509\r0.0043\rcesd\r-2.3499\r0.0070\rage × time\r-1.3805\r0.0317\rsmoke × time\r-14.2323\r\u0026lt;.0001\rdrug × time\r-1.7315\r0.8488\rpartners × time\r-0.3958\r0.7161\rcesd × time\r0.1585\r0.6899\rtime^2\r0.8753\r0.6187\rTable 1: Full linear mixed effects model estimate.\nAfter choosing the linear fixed effects model with random intercept and random slope to model the data, the next part is selecting a good combination of predictors that describe the CD4+ cell count data. A full model is fitted first. From Table 1, which show the estimated β, predictors that are not significant at p-value of 0.05 will be dropped and the predictors that are significant will be kept as a reduced model. Note the time^2 was included in the full model because of the nonlinear trend of time that was indicated in the response trend graph.\nThe predictors that are dropped are drug, drug × time, partners × time, cesd × time, and time^2. Even though the age predictor is not significant the interaction age × time is significant therefore the age predictor is kept in the reduced model.\nFull Model Reduced Model\rintercept\r790.11\r\u0026lt;.0001\r-2 Log Likelihood\r33603.4\r33600.9\rχ2 Test\r2.5\r2.5\rStatistic Degree of Freedom\r13\r8\rχ2 25,0.95\r11.070\r11.070\rTable 2: Likelihood Ratio test for two linear mixed effect models.\nHypothesis H1: Reduced Linear Mixed Effects Model Hypothesis H2: Full Linear Mixed Effects Model\nAfter fitting the reduced model, a likelihood ratio test was conducted between the full model and the reduced model. Table 2 shows the χ2 test statistic at 2.5 which is the difference between the -2 Log Likelihood of full model and reduced model. The degree of freedom for χ2 is the difference between the number of parameters in the full model and the number of parameters in the reduced model which is 5. The null hypothesis for the deviance test is the reduced model and the alternative hypothesis is the full model. Since the test statistic is 2.5 which is much less than 11.070, the reduced model is chosen.\n3.4 Final Model The equation listed below is the selected model that best represent the CD4+ cell count data and the best explanation of the data. With this model, the investigation can proceed to answer the aim of the investigation.\nYij = β0 + β1 timeij + β2 ageij + β3 smokeij + β4 partnersij + β5 cesdij + β6 ageij × timeij + β7 smokeij × timeij + b0i + b1i × timeij + eij\r=791.05 − 80.1857timeij + 1.4697ageij + 38.0785smokeij + 7.0434partnersij − 2.2867 cesdij − 1.3400 ageij × timeij − 13.2674 smokeij × timeij + b0i + b1i timeij + eij (1)\rWhere b0i represents the random intercept for each individual and b1i represents the random slope for each individual.\nThe model can be rewritten in matrix notation\nYi=Xiβ+Zibi +ei, i=1,…,N,j=1,…,ni (2) where Y i is a vector of size ni × 1 representing observations for ith individual, j represent the jth measurement for ith individual, Xi is a ni × p design matrix of p independent fixed effect variables, Zi is a ni × q design matrix of q independent random effect variables, β is a vector of size p × 1 representing fixed effect parameters, bi is an independent vector of q × 1 size representing random effects with MVN(0,G) distribution (Multivariate Normal), and ei represents an independent vector of random errors of size ni ×1 with MVN(0,Ri) distribution. The ei are independent of bi.\nThe Ri represent within-subject variance. Linear fixed effects model break Ri down into two sources of within-subject variance, serial correlation and measurement error. The measurement error variance (τ^2) is equal to 59104. The serial correlation variance (σ^2) is 1.0649. The G matrix represents the between-subject variance.\nSee paper for more matrix notations… \u0026gt;__\u0026lt;\nEtc… Please see paper for results, SAS codes, R codes, and conclusion. The blog post is getting long.\nPost Mordem Well… translating a paper into a blog post is terrible. The paper is too academic with high domain assumption and an abstract and a link to the paper is sufficient.\nEtc.. The Freddie Mercury picture is taken from pixabay.","date":"2018-06-07T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/linear-mixed-effects-models-for-cd4-cell-counts-in-men-with-hiv/freddie-mercury-memorial-779956_640_hu53777eb8fcd46320722b3f01d82c23b1_63523_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/linear-mixed-effects-models-for-cd4-cell-counts-in-men-with-hiv/","title":"Linear Mixed Effects Models for CD4+ Cell Counts in Men with HIV"},{"content":"\n","date":"2017-11-09T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/got-to-meet-with-mr-hadley-wickham/R_logo_hu960ac6e9e6edf830bb37fcf8948b1fe1_77977_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/got-to-meet-with-mr-hadley-wickham/","title":"Got to meet with Mr. Hadley Wickham"},{"content":"Introduction I’m into light novels so I’ve decided to combine my love for data science and light novel.\nInformation Retrieval I started out by retrieving some data from online via scraping using scrapy. I love scrapy and highly recommend it for any serious web scrapping task.\nThe Data So what does the data look like?\n2739 novels.\nIt’s in a json format.\nThe columns are novel title, description, novel type, genre, tags, rating, language, authors, year, and license.\nExploratory Data Analysis For this portion I will be using R to do some EDA (❤ John Tukey).\nThere are eight languages in the data including 7 novels with no language category.\nThe languages are: Japanese, Chinese, Korean, Malaysian, Filipino, Indonesian, Thai, and Vietnamese.\nLanguages Number of Novels Average Ratings Japanese 1496 3.994248 Chinese 1059 3.978571 Korean 131 4.142424 Filipino 23 NA Indonesian 12 NA Thai 7 NA Malaysian 3 NA Vietnamese 1 NA Uncategorized 7 NA The average ratings only include novels that have at least 30 user ratings.\nI did not take any other rating from other countries because there are less than 30 novels. As a statistician I feel 30 or more is a sufficient number to represent the population for each category anything smaller than is insufficient.\nI plot a histogram plot for all novels from all countries with 30 or more user ratings. It is left skewed. While I can only speculate that people tend to rate for their favorite novels. It’s interesting because there is quite a lot of quality novels out there and many hover above 4.0 rating out of 5.0.\nThere is a small number with perfect five ratings. 19 novels with 5 ratings all of them have single digit number of users reviews except for one (“Mum, I Used to Hate You”). It have 18 users that reviewed it with a 5 rating.\nSweet let’s find novels that have high rating and at least 30 user reviews! I tried 4.5 at first but it’s a huge list at least 300+ so I decided to look for 4.7 ratings. There is exactly 75 novels with that criteria.\nHere’s the list and hope you guys find it useful.\nA Game To Make Him Fall\rA Will Eternal\rA Slight Smile is Very Charming\rAme no Hi no Iris\rAt the Northern Fort\rBy A Slight Mistake\rCultivation Chat Group\rClockwork Planet\rDemon Girl ~Tale of a Lax Demon~\rDungeon Defense\rEight Treasures Trousseau\rGekkou\rGolden Age Legitimate Fei\rHokuou Kizoku to Moukinzuma no Yukiguni Karigurashi\rHiraheishi wa Kako o Yumemiru\rHikaru ga Chikyuu ni Itakoro……\rI Reincarnated into an Otome Game as a Villainess With Only Destruction Flags…\rI Don’t Like The World, I Only Like You\rIt’s Because You Said There Would Be Candy!!\rJoy of Life\rKenkyo, Kenjitsu o Motto ni Ikite Orimasu\rKaze no Stigma\rKono Kamen no Akuma ni Sodan wo!\rKuzu to Kinka no Qualidea\rManuscript Screening Boy and Manuscript Submitting Girl\rMarietta-hime no Konrei\rMarginal Operation\rMaoyuu Maou Yuusha\rMimizuku to Yoru no Ou\rMondaiji-tachi ga Isekai kara Kuru Sou Desu yo?\rMulberry Song\rMy Death Flags Show No Sign of Ending\rNo Game No Life\rNobunaga’s Imouto is My Wife\rOokami to Koushinryou\rOverlord (LN)\rOuroboros Record ~Circus of Oubeniel~\rOur Second Master\rQuickly Wear the Face of the Devil\rRakuin no Monshou\rRain\rRelease that Witch\rRunning Away From The Hero!\rSansheng, Wangchuan Wu Shang\rSemi Datte Tensei Sureba Ryuu Ni Naru\rSweet Heart in Honeyed Desire\rTabi ni Deyou, Horobiyuku Sekai no Hate Made\rThe Bathroom Goddess\rThe Destruction of a Triad Boss Trilogy\rThe Girl Who Bore the Flame Ring\rThe Girl Who Ate a Death God\rThe Founder of Diabolism\rThe Legend of Sun Knight\rThe Grandmaster Strategist\rThe Magnificent Battle Records of A Former Noble Lady\rThe Princess Wei Yang\rThe Probability I Can Kill My Wife Without Being Found Out\rThe Other World Dining Hall (LN)\rThe Rebirth of the Malicious Empress of Military Lineage\rThe Scum Villain’s Self-Saving System\rThe Tang Dynasty’s Female Forensic Doctor\rThe Witch and the Gourd of Stories\rTo Be A Virtuous Wife\rThree Days of Happiness\rUchi no Musume no Tame naraba, Ore wa Moshikashitara Maou mo Taoseru kamo Shirenai (LN)\rUchi no Musume no Tame naraba, Ore wa Moshikashitara Maou mo Taoseru kamo Shirenai (WN)\rTsuyokute New Saga (LN)\rVermillion\rUtsuro no Hako to Zero no Maria\rWhy Is the Prettiest Girl in School Trying to Talk to a Loner Like Me during Lunch Break?\rWhen He Comes, Close Your Eyes\rVirtual World: Peerless White Emperor\rWoof Woof Story ~ I Told You I am a Rich Person’s Dog, Not Fenrir ~\rYahari Ore no Seishun Love Come wa Machigatte Iru\rYoujo Senki\rConclusion I think I’ll be doing more light novel analysis in the future.\nI think I’ll do NLP too something like sentiment analysis or something for those tags and categories. Of course this is when I have time.\nWhat Did I Get to Practice? (for me) My data science \u0026amp; statistic skills using R. My web scraping skill using scrapy. My devops skill, I made a custom vagrant for jekyll and used ansible to self provision. I created a new blog just for this post. I made a yummy pie chart. Etc.. The novel picture is taken from google searching for a CC license image.\n","date":"2017-07-17T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/light-novel-analysis-part-1/lightnovel_hue3f6c131a135f7a211aab575893b8d77_402324_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/light-novel-analysis-part-1/","title":"Light Novel Analysis (part 1)"},{"content":"Introduction So I’ve learned a little bit about Bayesian Hierarchical Modeling at FDA and decided to put down my thoughts and write about it more to reinforced what I’ve learned. I also want to try out some new javascript data visual libraries.\nA great book I’ve found is, “Introduction to Hierarchical Bayesian Modeling for Ecological Data” by Parent and Rivot [1].\nWhile at the FDA I code my own model without using any MCMC framework and it was very slow in R. I realize I need a MCMC framework under my toolbelt. After some research I decided on Stan using the rstan r package.\nThe Graph (not DAG; not a Bayesian network) Graph represents the salmon migration and birth cycle. Each edge represent a year pass. The nodes are square because they’re given. The information is given from previous knowledge.\nVariable\rDefinition\rWt\rSalmon Eggs\r0+\rYoung-of-the-year (hatched)\rPSm\rPre-smolts\rSm1\rSmolt after 1 year\rSp1\rReturns one year earlier than Sp2\rParr1\rSmaller juveniles left behind by Sm1\rSm2\rSmolt after 2 year\rSp2\rReturns one year after Sp1\rThe Models - Introducing Probability into the Graph\rWe’re going to take the graph that represent Salmon’s migration cycle and introduce uncertainty to it (model it via probability). By doing this we create a new graph that is complete different from the Salmon’s migration cycle graph. It is a graph base on probability view.\rWe go through each square node and one by one apply a model and probability to it.\rModel is time base, t will represent a particular year.\rSp t = Sp1 t + Sp2 t = # of spawners at t-th year\rW t = # of eggs spawned by the adults returning in year t\r0+ t = Young-of-the-year at t-th year\rPSm t = pre-smolts at t-th year\rSm1 t = 1+ smolts (1 year to smolt) at t-th year\rP1 t = Parr1 = smaller juveniles left behind by Sm1 at t-th year\rSm2 t = 2+ smolts (2 years to smolt) at t-th year\rSpawners -\u0026gt; Eggs\rW t = Sp t ⋅ P_f ⋅ fec\rW t = # of eggs spawned by the adults returning in year t\rSp t = # of spawners = Sp1 + Sp2\rP_f = proportion of females\rfec = mean of fecundity (fertility)\rEggs -\u0026gt; 0+ juveniles\rThis is Ricker Cruve model with parameters (α,β) which is a classic discrete population model.\r0+t+1 = α ⋅ Wt ⋅ e-β ⋅ Wt ⋅ eεt where εt ~iid N(0, σ2)\r0+t+1 = freshwater production of juveniles resulting from the reproduction of the spawners returning in year t 0+ juveniles -\u0026gt; Smolts\nPSmt+2 ~ Binomial(0+t+1, γ0+) = # of 0+t+1 will survive and migrate to PSmt+2\nSm1t+2 ~ Binomial(PSmt+2, θSm1) = # of PSmt+2 will survive and migrate as 1+smolts (Sm1)\nSm2t+3 ~ Binomial(Parr1t+2, γparr1) = # of Parr1t+2 will survive and migrate as 2+smolts (Sm2)\nPSmt+2 = young-of-the-year 0+t+1 will survive next spring year t+2γ0+ = survival rate of 0+θSm1 = proportion of pre-smolts will migrate as 1+Smolts (survival rate)γparr1 = survival rate of parr1\rSp1t+3 ~ Binomial(Sm1t+2, γSm)\nSp2t+4 ~ Binomial(Sm2t+3, γSm)\nγSm = survival rate\rLearning from observations\nThese two are observed and given:\nCSm1,t = observations = # of smolts caught downstream trap\nπSm = trap efficiency\nUsing these data points we can figure out the unknowns.\nOur unknowns, the parameters, are: α, β, σ, γ0+, θsm1, γParr1, γSm\n# of smolts caught downstream trap can be model as a binomial distribution either the smolt is caught or not.\nCSm1,t ~ Binomial(Sm1t, πSm)\n*Note (advance): observations assume Bayesian’s property of exchangability\nThe Models - Creating a probability graphical model\r0+t+1 = α ⋅ Wt ⋅ e-β ⋅ Wt ⋅ eεt where εt ~iid N(0, σ2)\n0+t+1 = freshwater production of juveniles resulting from the reproduction of the spawners returning in year t\rPSmt+2 ~ Binomial(0+t+1, γ0+) = # of 0+t+1 will survive and migrate to PSmt+2\nγ0+ = survival rate of 0+\rSm1t+2 ~ Binomial(PSmt+2, θSm1) = # of PSmt+2 will survive and migrate as 1+smolts (Sm1)\nPSmt+2 = young-of-the-year 0+t+1 will survive next spring year t+2θSm1 = proportion of pre-smolts will migrate as 1+Smolts (survival rate)\rSm2t+3 ~ Binomial(Parr1t+2, γparr1) = # of Parr1t+2 will survive and migrate as 2+smolts (Sm2)\nSp1t+3 ~ Binomial(Sm1t+2, γSm)\nSp2t+4 ~ Binomial(Sm2t+3, γSm)\nNow we put all the parts together into graph. Okay, now that we got the probability graphical model down we can figure out the joint probability distribution.\nP(Jt) = ?\nStep 1. Looking at the graph, we’re going to start with all nodes with no parent: α, β, σ, Wt, γ0+, θSm1, γParr1, and γSm.\nP(Jt) = P[α] ⋅ P[β] ⋅ P[σ] ⋅ P[Wt] ⋅ P[γ0+] ⋅ P[θSm1] ⋅ P[γParr1] ⋅ P[γSm] … Step 2. Now we’re going to look at the nodes with parents.\n0+t+1 is P[0+t+1 | Wt, α, β, σ]PSmt+2 is P[PSmt+2 | 0+t+2, γ0+]Sm1t+2 \u0026amp; Parr1t+2 is P[Sm1t+2, Parr1t+2 | PSmt+2, θSm1]. Notice how complex this one is. It is because Sm1 and Parr1 both share the same parameters.P[Sp1t+3 | Sm1t+2, γSm]P[Sm2t+3 | Parr1t+2, γParr1]P[Sp2t+4 | Sm2t+3, γSm]\rP(Jt) = P[α] ⋅ P[β] ⋅ P[σ] ⋅ P[Wt] ⋅ P[γ0+] ⋅ P[θSm1] ⋅ P[γParr1] ⋅ P[γSm] \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; \u0026nbsp; ⋅ P[0+t+1 | Wt, α, β, σ] ⋅ P[PSmt+2 | 0+t+2, γ0+] ⋅ P[Sm1t+2, Parr1t+2 | PSmt+2, θSm1]\r\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; ⋅ P[Sp1t+3 | Sm1t+2, γSm] ⋅ P[Sm2t+3 | Parr1t+2, γParr1] ⋅ P[Sp2t+4 | Sm2t+3, γSm] Okay so what? Where’s the Bayesian network?\rNot yet. The book needs to introduce the concept of a simple model vs a hierarchical model and some terminology.\nSo far we haven’t introduce any observational variable (random variable) at all.\nθ represents parametersZ represents latent parametersY represents the output Random Variable. (little y represent the realization/sample of Y random variable).\rLeft is a simple model. The right graph is a hierarchical model.\nZ represents latent variables (nuisance variables), basically variables we don’t really care, also they’re hidden we don’t observed it directly like Y. Y represents observations. Observations are random so Y is capitalized and smaller y is the realization of Y or a sample of Y. The node is pink because it is an observable.\nP[θ, Z, Y] = P[θ] ⋅ P[Z | θ] ⋅ P[Y | θ, Z]\nWell first what’s the experiment?\nFor this it’s salmon captures and they’re model via binomial distribution either you catch the fish or not.\nNotice the C stands for catches.\nC0+, t+1 ~ Binomial(0+t+1, π0+)CSm1, t+2 ~ Binomial(Sm1t+2, πSm)CSm2, t+3 ~ Binomial(Sm1t+3, πSm)CSp1, t+3 ~ Binomial(Sp1t+3, πSp)CSp2, t+4 ~ Binomial(Sp2t+4, πSp)\rOnce again the squares represent known/given values (the π’s are given). The pink circle means observed values. Pink in general means they’re known either by given or by observations. The purple boxes represent grouping and group the nodes into their respective group.\nOk. Finally, we got a Bayesian network. Really, what now?\nHow does y (the sample or realization of Y) fits in this fancy graph?\nWhat happen when the Observation is available?\rBefore that notice how we build the model and the direction. The direction is downward from the Salmon cycle toward the latent variable and then towards the obsevation.\nWhy did the book brought this up? It is because when you train the model using the data/observations that are available you go in the opposite direction.\nYou start at the Y (observation layer and Y is a random variable) and Y is now, Y = y, since little y is the realization of random variable Y. y is a sample of Y or the data (values not just some placeholder variable). And you go up to latent layer and then to the parameter later.\nLet’s see it mathematically:\nHere’s the joint probability:\nP[Y, θ, Z]\nNow here’s the joint probability with Y = y, when we have data to train the model and find the paramenter.\nP[θ, Z | Y = y]\nGiven Y = y, the observations propagate upward from the observation to the latent layer to the parameter layer.\nThis is how you train the model after you are done creating the model.\nYou can see the Bayes Rule connection too right? We’re always dealing with Joint Probability and Conditional Probability.\nBayesian make it so that they’re conditionally independent. This is one of the property of Bayesian statistic.\nThis is now a posterior distribution. Posterior being after the data. Prior distribution is before the data.\nP[θ, Z | Y = y] = posterior distributionundefined\rI’m going to repeat it again.\nPosterior is after the data have been inputed.\nPrior is before the data. It is your prior belief.\nIn Bayesian you need to supply a belief in form of a prior distribution. It’s weird but don’t worry if you don’t know anything then you can use a noninformative prior distribution.\nThe belief thing is also away to encode expert belief too.\nSo given what we have now, we just have to apply Bayes’ Rule to the conditional probability and you get your parameter values.\nBayes’ Rule\rP[θ Z | Y = y] = P[θ, Z, Y = y] / P[Y = y]\nSome stat here and you get.\nP[θ Z | Y = y] ∝ P[θ] ⋅ P[Z | θ] ⋅ P[Y = y | θ, Z]\nConclusion\rI highly recommend this book. Andrew Gelman’s DBA book is more PhD level and his approach is not graphical like this but more mathy. Being visual this book helps a lot into tying things together.\nThere was no observations/data and no code for this chapter. Ah dangit. Well until next time, stay tuned for the next episode of Bayesian man.\n1Buy the book if you like what you see on the post. This is basically my notes on chapter 1 of the book. It’s an amazing book and I highly recommend it.\nWhat did I learn about myself\nI’m glad I’m reviewing this chapter of the book again. I have a confession to make, if I want to understand a material/subject I need to read 3 times and do projects on it and a review of what I’ve learned. I need tons of practice. I guess this is one of the reason why I started this blog.\nThis chapter ties in again DAG, Bayes’ Rule, and conditional probabilities. Good refresher and clear up things that I was wrong about. Especially the salmon breeding cycle, I didn’t think about the fact that it wasn’t a DAG. And that from that model we create a Bayesian Graph Model (DAG).\nI think I’ll go through each chapter of this book as a refresher while playing with javascript graphical libraries and hopefully learn Stan. I need to make sure I didn’t miss out on anything from the first reading.\nWhat Did I Get to Practice? (for me)\nBayesian Hierarchical Modeling using rstan.Tried out a javascript data visualisation library, cytoscape.js, for modeling graphs.Gets to refresh Bayesian Graphical Model (Bayesian Network).\rRough Roadmap for Bayesian HM\nFinish off this book. Introduction to Hierarchical Bayesian Modeling for Ecological Data (Chapman \u0026amp; Hall/CRC Applied Environmental Statistics)Read this for Hamiltonian Markov Chain(Statistics in the social and behavioral sciences series) Gill, Jeff-Bayesian Methods A Social and Behavioral Sciences Approach-CRC Press (2014)Read https://arxiv.org/abs/1111.4246 an implementation of HMCMeasure theory videosDBA 3 reread again learning Dirichlet Process\rEtc..\rIntroduction to Hierarchical Bayesian Modeling for Ecological Data (Chapman \u0026amp; Hall/CRC Applied Environmental Statistics) The book link is Amazon affiliated. If you get it at CRC publishing you can get it 20 bucks cheaper if you use a discount code, just that it takes longer to ship. Also note I would recommend reading “Doing Bayesian Data Analysis” first before even trying to get into Hierarchical Modeling.Would like to thank this website for all the html mathematical notations.\rThe salmon sushi picture was taken from pixabay under creative common license.\r","date":"2017-07-15T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/book-note-intro-to-hierarchical-bayes-modeling-eco-data-chp-one/salmon_sushi_hu4711793190d15acc5555df5b859ceb84_343879_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/book-note-intro-to-hierarchical-bayes-modeling-eco-data-chp-one/","title":"Book Note: Introduction to Hierarchical Bayesian Modeling for Ecological Data, Chapter 1"},{"content":"Note: This post was created awhile back on another platform (Tumblr) and I migrated to my current one.\nArray Initialization Using new Array Constructor 1 2 3 val arrayOfStrings = new Arrayrings(0) = \u0026#34;Hi\u0026#34; arrayOfStrings(1) = \u0026#34; array\u0026#34; arrayOfStrings(2) = \u0026#34; of Strings.\\n\u0026#34; Using Array Factory Method 1 val arrayOfStrings = Array(\u0026#34;Hi\u0026#34;, \u0026#34; array\u0026#34;, \u0026#34; of Strings.\\n\u0026#34;) Printing Array Elements 1 2 for (i \u0026lt;- 0 to 2) print(arrayOfStrings(i)) Output: 1 Hi array of Strings. Understanding val and Mutability Although val makes a variable immutable, it does not make the contents of an array immutable. You cannot reassign arrayOfStrings to a new array, but you can modify its elements:\n1 2 3 arrayOfStrings(0) = \u0026#34;Bye\u0026#34; for (i \u0026lt;- 0 to 2) print(arrayOfStrings(i)) Output: 1 Bye array of Strings. Why Does This Happen? Even though val prevents reassignment of the variable, it does not make the object it points to immutable. The array itself remains mutable, meaning its elements can be modified. However, you cannot assign arrayOfStrings to a completely new array.\n","date":"2011-07-03T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/arrays-containers-in-scala-mutable/","title":"Arrays (Containers in Scala) [Mutable]"},{"content":"Note: This post was created awhile back on another platform (Tumblr) and I migrated to my current one.\nwhile Loop 1 2 3 4 5 var i = 0 while (i \u0026lt; 10) { println(i) i += 1 } for Loop Using a Range (until) 1 2 3 for (i \u0026lt;- 0 until 10) { println(i) } Iterating Over a Collection 1 2 3 for (s \u0026lt;- listOfStrings) { // Do something with s } foreach Loop (More Functional Approach) 1 2 3 4 5 listOfStrings.foreach(doSomething) def doSomething(s: String): Unit = { // Process s } Reference Loops in Scala – Matt Hicks\n","date":"2011-07-01T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/loops-in-scala/","title":"Loops in Scala"},{"content":"NOTE: This is a very old post that I\u0026rsquo;ve migrated from my tumblr account.\nI have matured since then and continue to learn, striving to remain humble with a mindset of humility.\nDefining Variables in Scala Two Types of Variables val (immutable) var (mutable) Example: Immutable val 1 2 3 val hello = \u0026#34;Hello Scala\u0026#34; hello = \u0026#34;Hello again\u0026#34; // ERROR: can only assign once println(hello) Note: val is not the same as const in C++. (See: Java final vs. C++ const.)\nExample: Mutable var 1 2 3 var goodbye = \u0026#34;Hello Scala\u0026#34; goodbye = \u0026#34;Goodbye Scala\u0026#34; println(goodbye) ","date":"2011-06-29T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/defining-variables-in-scala/","title":"Defining Variables in Scala"},{"content":"NOTE: This is a very old post that I\u0026rsquo;ve migrated from my blogger account.\nI have matured since then and continue to learn, striving to remain humble with a mindset of humility.\nScala Function Basics Defining a Basic Function 1 def functionName() = { /* function body */ } Function with a Parameter 1 def functionName(param1: ParamType) = { /* function body */ } Function with a Return Type 1 def functionName(param1: ParamType): ResultType = { /* function body */ } Examples Simple Function 1 def printHello() = { println(\u0026#34;Hello, world!\u0026#34;) } Function with a Parameter 1 def echo(str: String) = { println(str) } Function with a Return Type 1 2 3 4 def echo(str: String): Int = { println(s\u0026#34;The length of \u0026#39;$str\u0026#39; is: \u0026#34;) str.length } Reference Fun with Scala Functions\n","date":"2011-06-27T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/scala-function-basics/","title":"Scala Function Basics"},{"content":"NOTE: This is a very old post that I\u0026rsquo;ve migrated from my blogger account.\nI have matured since then and continue to learn, striving to remain humble with a mindset of humility.\nInstalling Scala 2.9 on Ubuntu Steps to Install Scala (Latest Version as of Writing: 2.9) 1. Download Scala Open your browser and go to the Scala downloads page.\nFind the appropriate package for Unix, Mac OS X, or Cygwin, and either download it manually or copy the direct link to the package.\n2. Open Terminal \u0026amp; Navigate to Root 1 cd / 3. Create /opt Directory (If It Doesn\u0026rsquo;t Exist) Ubuntu does not include an /opt directory by default, so create one manually:\n1 sudo mkdir /opt 4. Navigate to /opt 1 cd /opt 5. Download Scala Replace the version number with the latest available if necessary:\n1 sudo wget http://www.scala-lang.org/downloads/distrib/files/scala-2.9.0.1.tgz 6. Extract the Package 1 sudo tar zxvf scala-2.9.0.1.tgz 7. Remove the Archive File 1 sudo rm scala-2.9.0.1.tgz 8. Add Scala to Your PATH Edit your ~/.bashrc file to include Scala’s binary path:\n1 nano ~/.bashrc Add the following line at the end of the file:\n1 export PATH=/opt/scala-2.9.0.1/bin:$PATH 9. Apply the Changes 1 source ~/.bashrc References Original Ubuntu Forums Thread ","date":"2011-06-26T00:00:00Z","permalink":"https://mythicalprogrammer.github.io/p/installing-scala-2-9-on-ubuntu/","title":"Installing Scala 2.9 on Ubuntu"},{"content":"NOTE: This is a very old post that I\u0026rsquo;ve migrated from my blogger account.\nI have matured since then and continue to learn, striving to remain humble with a mindset of humility.\nPreface There was a man, to be more specific a developer, that is I. I\u0026rsquo;m going to learn Scala and writing things down is going to help me. These are my notes for the book Programming In Scala by Martin Odersky, Lex Spoon, Bill Venners. That is all.\nWhy Scala? Pro:\nIt is a great balance between readability like Ruby and Python but with type define. Got a great parallel library that is model after Erlang. Going to help me learn functional language.\nGot a web framework.\nFast because it uses JVM.\nPolygot.\nCon:\nIt uses JVM.\nOwn by Oracle which does not understand open source and is recently a threat to open source.\nThe light at the end of the tunnel:\nThere are open source implementation of JVM out there. Con, crashes a lot cause oracle will not give them the TCK license. Oh wellz. I\u0026rsquo;m also bias against Java coming from a C++/PHP background.\n","date":"2011-06-25T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/why-scala/Scala-full-color_hu842710b4f217257b987be0cb1e777b1a_23221_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/why-scala/","title":"Why Scala?"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nSetting Up a Debian (Lenny) Server on Linode This tutorial is a refined version of the SliceHost guide for setting up a Debian 5.0 (Lenny) server.\nWhy a Virtual Server? If you need a web server without paying for a dedicated physical machine, a virtual private server (VPS) is a great alternative. After comparing different providers, I chose Linode because they offered more RAM for the price.\nServer Setup Steps 1. Load Debian Lenny Image Using Linode’s manager, load up Debian Lenny’s image and set up the root password.\n2. SSH into Your Server For Windows users, download PuTTY to connect via SSH.\nExample:\n1 ssh root@123.45.67.123 Basic Configurations 3. Enable Color Console Color in the terminal helps differentiate files, directories, and commands.\nNavigate to the root directory: 1 cd /root Edit .bashrc: 1 nano .bashrc Add/uncomment the following: 1 2 3 4 5 6 # Enable colorized ls export LS_OPTIONS=\u0026#39;--color=auto\u0026#39; eval \u0026#34;`dircolors`\u0026#34; alias ls=\u0026#39;ls $LS_OPTIONS\u0026#39; alias ll=\u0026#39;ls $LS_OPTIONS -l\u0026#39; alias l=\u0026#39;ls $LS_OPTIONS -lA\u0026#39; 4. Create a New User with Root Privileges Using root all the time isn’t safe. Create an admin user instead:\nCreate an admin group: 1 groupadd admin Edit sudoers: 1 visudo Add the following line: 1 2 ## Allows people in group admin to run all commands admin ALL=(ALL) ALL Add a user to the group: 1 2 adduser anthony usermod -a -G admin anthony Switch to the new user: 1 su anthony 5. Secure SSH Configuration Edit the SSH config file:\n1 sudo nano /etc/ssh/sshd_config Modify these lines:\n1 2 3 4 5 Protocol 2 PermitRootLogin no PasswordAuthentication no UseDNS no AllowUsers anthony Restart SSH for changes to take effect:\n1 sudo service ssh restart Firewall (iptables) Setup 6. Check Current Firewall Rules 1 sudo iptables -L If no rules exist, add some:\n7. Create a Firewall Rules File 1 2 sudo mkdir /root/firewall sudo nano /root/firewall/iptables.current.rules Add the following:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 *filter # Allow loopback traffic and drop unwanted traffic to 127.0.0.1 -A INPUT -i lo -j ACCEPT -A INPUT ! -i lo -d 127.0.0.0/8 -j REJECT # Accept established inbound connections -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # Allow outbound traffic -A OUTPUT -j ACCEPT # Allow HTTP, HTTPS, and SSH -A INPUT -p tcp --dport 80 -j ACCEPT -A INPUT -p tcp --dport 443 -j ACCEPT -A INPUT -p tcp --dport 22 -j ACCEPT # Allow ping -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT # Log denied packets -A INPUT -m limit --limit 5/min -j LOG --log-prefix \u0026#34;iptables denied: \u0026#34; --log-level 7 # Reject all other inbound traffic -A INPUT -j REJECT -A FORWARD -j REJECT COMMIT 8. Apply the Firewall Rules 1 sudo /sbin/iptables-restore \u0026lt; /root/firewall/iptables.current.rules Check the applied rules:\n1 sudo iptables -L 9. Persist Firewall Rules After Reboot Create a script:\n1 sudo nano /etc/network/if-pre-up.d/iptables Add:\n1 2 #!/bin/sh /sbin/iptables-restore \u0026lt; /root/firewall/iptables.current.rules Make it executable:\n1 chmod +x /etc/network/if-pre-up.d/iptables To back up current rules:\n1 sudo iptables-save -c \u0026gt; iptables-backup.txt Other Configurations 10. Set Server Timezone 1 sudo dpkg-reconfigure tzdata Follow the on-screen menu.\n11. Set Server Locale 1 sudo dpkg-reconfigure locales Select en_US.UTF-8 UTF-8 or another preferred locale.\nDomain Name Setup I registered my domain with GoDaddy. During setup, I provided these Linode name servers:\n1 2 3 4 5 ns1.linode.com ns2.linode.com ns3.linode.com ... ns6.linode.com Conclusion This guide helps you set up a Debian (Lenny) server on Linode securely, including SSH hardening, user management, and firewall setup. You can now proceed with hosting your applications.\n","date":"2010-07-02T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/my-webserver-setup-part-1/63200811359PM_wait_hu3b48bfc24348c64bbfe9b91cb2a5f666_29920_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/my-webserver-setup-part-1/","title":"My Webserver Setup part 1"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nReading List Programmers are Tiny Gods By Derek Powazek\nIn the Beginning… Was the Command Line By Neal Stephenson\nRead Online Download Wikipedia Entry 📌 Also check out this StackOverflow discussion on favorite programming essays.\nCredits Image by Pexels from Pixabay ","date":"2010-06-19T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/recommended-reads-on-programming/ganesha-1853602_1280_hue069f74bd69a137084dc51a02c62c0d0_171343_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/recommended-reads-on-programming/","title":"Recommended Reads on Programming"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nInstalling PEAR on WAMP Step-by-Step Guide 1. Follow This Tutorial I followed this tutorial to install PEAR on WAMP.\nHowever, the tutorial misses the environment variables installation part (it only covers Vista).\n2. Setting Up Environment Variables To set up environment variables on Windows, follow these steps (source: Microsoft):\nRight-click My Computer, then click Properties. Click the Advanced tab. Click Environment Variables. 📸 Example Screenshot:\n3. Editing the Path Variable Find the System variables section and look for the Path variable.\nEdit the Path variable and add the following (separated by a semicolon):\n1 c:\\wamp\\bin\\php\\php5.3.0 📌 Important: If the command line is already open, exit and reopen it for the changes to take effect.\n4. Verifying the Installation Run the following command in the terminal:\n1 path If everything is set up correctly, you should see the updated path including PEAR.\n📸 Verification Screenshot:\nConclusion Setting up PEAR on WAMP is straightforward, but you need to manually configure the environment variables for proper installation. Make sure to restart your terminal after making changes, and you should be good to go! 🚀\nCredit Image by Anna Arzamasova from Pixabay ","date":"2010-05-29T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/php-howto-installing-pear-with-wamp-on-window/pear-6136656_1280_hu5438825b9b6d1014226d20d231e650c2_105689_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/php-howto-installing-pear-with-wamp-on-window/","title":"PHP howto: Installing PEAR with WAMP on Window"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nNote I\u0026rsquo;ve matured now and have decided to not post any new book reviews on books that I do not like. I apologize in advance for my negative review of this book and I did not intend to be overly negative. I was young and am still learning.\nThe post:\nLearning PHP, MySQL, and JavaScript A Step-By-Step Guide to Creating Dynamic Websites (Animal Guide)\nMy Review I needed to review PHP since many things have changed. I first tried Head First PHP \u0026amp; MySQL, but it wasn’t technical enough for me. While I initially thought its teaching style would help, it didn’t work out.\nThis book assumes some programming knowledge, which is great because it moves at a faster pace. Unlike Head First PHP \u0026amp; MySQL, which is slow, this book goes straight to the key subjects—PHP, MySQL, and even touches on other topics. However, when I reached the JavaScript section, I stopped reading.\nPros \u0026amp; Cons ✅ What I Liked Fast-paced if you already know some programming. Great MySQL chapters – I learned about MySQL database engines like InnoDB and ISAM and how to search databases like a search engine. Good for PHP basics – helped me dive back into PHP and solidify the fundamentals of PHP5. ❌ What I Didn\u0026rsquo;t Like Too many code errors – you can find them listed here. Confusing examples – Some techniques shouldn\u0026rsquo;t even be used in real-world applications. PHP authentication example is flawed – The book combines HTTP authentication with PHP sessions, but doesn\u0026rsquo;t explain how to log out properly. Deleting browser cookies doesn’t work, and I had to Google better solutions (hint: use a logout flag in the script). Smarty introduction is weak – Installation instructions were unclear, which is why I wrote a separate guide for Windows XP. No Object-Oriented PHP – All PHP examples are procedural, with no coverage of OOP in PHP5. Terrible JavaScript section – The JavaScript coding style is ugly, doesn’t follow best practices, and lacks proper variable declarations (var variable1) and semicolons. A better beginner JavaScript book would be a wiser choice (I\u0026rsquo;ll post a review of one soon). Final Verdict This book is a basic introduction to PHP for those with a programming background. However, it does not cover Object-Oriented PHP5 at all.\nI’d rate it ⭐️⭐️⭐️ (3/5 stars) because it helped me refresh my PHP knowledge, but I wouldn’t recommend buying it—especially if you’re looking for advanced topics or modern best practices.\n📌 Warning: I only read up to Chapter 16 (out of 20). I stopped when I reached JavaScript.\nOh, and if you click the image and buy it from Amazon, I get some store credit for more books—but honestly, this isn’t worth buying. 😉\n","date":"2010-05-17T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/book-review-learning-php-mysql-and-javascript/lrg_hu6175601c20069418e0467d5bd0e815e7_73566_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/book-review-learning-php-mysql-and-javascript/","title":"Book Review: Learning PHP, MySQL, and JavaScript: A Step-By-Step Guide to Creating Dynamic Websites (Animal Guide)"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nNote: In order to mount, you need GNU yak/water-buffalo and apparently a Lion.\nMounting an External Hard Drive on Linux If you have an external hard drive formatted with FAT32 or FAT16, you can both read and write to it without issues.\nHowever, if your hard drive uses the NTFS file system, you will encounter read-only access by default. This is due to FOSS (Free and Open Source Software) legal restrictions preventing full NTFS write support. The constant \u0026ldquo;Read-only file system\u0026rdquo; warning can be frustrating!\nSolution: Enabling NTFS Write Support The solution is to use ntfs-3g, which allows writing to NTFS partitions. Here\u0026rsquo;s a quick summary:\nInstall ntfs-3g\nSearch for and install the ntfs-3g package using your package manager.\nExample for Debian/Ubuntu:\n1 sudo apt install ntfs-3g Create a Mount Directory\nBefore mounting, create a directory to serve as the mount point.\nExample:\n1 sudo mkdir /mnt/window Find Your External Hard Drive Name\nUse fdisk to list available drives and find your external drive based on size:\n1 sudo fdisk -l If you’re using a USB drive, it is likely to be /dev/sdb.\nEdit /etc/fstab to Mount Automatically\nOpen the file in a text editor:\n1 sudo nano /etc/fstab Add the following line:\n1 /dev/sdb1 /mnt/window ntfs-3g defaults 0 0 Mount the Drive\nRun the mount command to apply changes:\n1 sudo mount -a ","date":"2010-05-16T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/mounting-an-external-ntfs-harddrive-on-linux-for-writing/Epic_Mount_hud469f350a37581c1e52440be4b546b36_37249_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/mounting-an-external-ntfs-harddrive-on-linux-for-writing/","title":"Mounting an External ntfs harddrive on Linux for writing"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nSo my landlord computer is shot so he wants the file. Problem is his filesystem is dead, his master boot record is shot to death beyond mountable. So what to do\u0026hellip;\nYou do this:\nhttp://www.debian-administration.org/articles/420\nIt didn\u0026rsquo;t work so I did PhotoRec which is cover in the above link and retrieve files. It took 160 passes and it still didn\u0026rsquo;t finish so I just grab what it retrieved.\nImage by Milos Duskic from Pixabay\n","date":"2010-05-16T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/recovering-harddrive-with-dead-filesystem/skull-1193784_1280_hu093210eea6715fd2f56974a0bddc1253_319048_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/recovering-harddrive-with-dead-filesystem/","title":"Recovering Harddrive with dead filesystem"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nSo after using Dreamweaver CS3 for a couple of months now, I felt it was lacking. It wasn\u0026rsquo;t as good as Microsoft Visual Studio. One of the things it\u0026rsquo;s lacking is a good auto-complete. The way Dreamweaver CS3 handles most of the coding is annoying and not as natural as Microsoft Visual Studio.\nI\u0026rsquo;ve googled a bit and found out about Eclipse IDE with PDT. So far, it\u0026rsquo;s a great IDE. I do not know all about it but just enough through these videos:\nNote: Code Assist is not on by default, so you need to go to:\nWindow -\u0026gt; Preferences -\u0026gt; PHP -\u0026gt; Code Assist\nCheck the \u0026ldquo;Enabled auto activation\u0026rdquo; checkbox. The default 200 ms delay is long, so I edited it to 20 ms.\nImage by Stefan Keller from Pixabay\n","date":"2010-05-08T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/finding-a-good-php-ide-eclipse-pdt/archway-6915701_1280_hua59ebd0fb34f35215d7a7f4ce42f3c3f_259565_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/finding-a-good-php-ide-eclipse-pdt/","title":"Finding a good PHP IDE - Eclipse + PDT"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nI got this from here: http://news.php.net/php.smarty.dev/2703\nSteps to Install Smarty: 1. Download Smarty 2. Extract Smarty Extract it outside of the www folder (e.g., C:\\wamp).\nRename the Smarty.x.x.x folder to smarty.\n3. Edit php.ini To do this, left-click on the WAMP icon in the system tray, under the PHP menu, there should be a php.ini option.\nExample configuration:\n1 include_path = \u0026#34;.;C:\\wamp\\smarty\\libs\u0026#34; WARNING: Copy-pasting might create errors with single and double quotes. Make sure to type them manually.\n4. Restart All Services Click on the WAMP icon in the system tray and select Restart All Services.\n5. Create Required Folders In your root www folder, create a directory named smarty, and within that folder, create:\ntemplates configs Outside of www, within C:/wamp/smarty, create:\ntemplates_c cache Note: There are security concerns for live setups, but for localhost, this is fine. Always use Linux for live testing.\n6. Create an HTML File Inside www or any subfolder within www, create a file (e.g., index.html).\n7. Create the Template File Create index.tpl and place it inside www/smarty/templates.\nFor more details, refer to:\nhttp://news.php.net/php.smarty.dev/2703\nNote: Blogspot may parse out HTML tags, so some code might not be displayed correctly.\n","date":"2010-05-07T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/installation-for-smarty-php-on-wamp/smarty_template_logo_hudef4205d41433ab5e977d39b2b368b5f_12165_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/installation-for-smarty-php-on-wamp/","title":"Installation for Smarty PHP on WAMP"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nTo find the fastest Internet in your area:\nnamebench is a Google project that will find the fastest DNS around your area. It takes a while. Free Fast DNS Free Public DNS Server Service provider: Google\n8.8.8.8 8.8.4.4 Service provider: ScrubIt\nPublic DNS server address:\n67.138.54.100 207.225.209.66 Service provider: DNS Advantage\nDNS Advantage free DNS server list:\n156.154.70.1 156.154.71.1 Service provider: OpenDNS\nOpenDNS free DNS server list:\n208.67.222.222 208.67.220.220 Service provider: vnsc-pri.sys.gtei.net\nPublic Name Server IP address:\n4.2.2.1 4.2.2.2 4.2.2.3 4.2.2.4 4.2.2.5 4.2.2.6 Fast DNS made possible thanks to this site.\n","date":"2010-04-21T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/make-your-internet-faster-with-free-fast-dns/dns-recrussion-big_hu21fb3675d809fff707a67f40f2b60edb_29768_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/make-your-internet-faster-with-free-fast-dns/","title":"Make your internet faster: Faster DNS \u0026 Free Fast DNS"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nNeeded to change the timezone on a server to match our client.\nRun this command:\n1 sudo dpkg-reconfigure tzdata And it\u0026rsquo;ll bring up a GUI-like command line interface where you can select options using the space bar, tab through choices, and press enter to confirm. Real simple.\nThanks to:\nhttp://www.zeitoun.net/articles/timezone-change-debian-lenny/start\nImage by Alexa from Pixabay\n","date":"2010-04-11T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/change-timezone-debian-lenny/clock-1392328_1280_hu08063bd89c294591d5773c7c7f2f2d63_614037_120x120_fill_q75_box_smart1.jpg","permalink":"https://mythicalprogrammer.github.io/p/change-timezone-debian-lenny/","title":"Change timezone Debian Lenny"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nHowto install PECL uploadprogress I need the uploadprogress PHP module for jQuery progress bar. The reason why my boss and I chose this progress bar over the others out there is because this one does not use Flash. Flash has some annoying bugs, making web development frustrating, and at the same time, it makes our code ugly—full of band-aids and workarounds.\nFurthermore, it was difficult to find any upload module for jQuery that doesn\u0026rsquo;t require Flash. The reason for this is that JavaScript runs on the client side and cannot track progress on the server side. So how can the progress bar gauge the completion percentage? The answer is a PHP module named uploadprogress.\nAnyway, in most Linux distributions, you install the module and add a line in php.ini such as:\n1 extension=uploadprogress.so and you\u0026rsquo;re done. Not in Debian!\nStep 1: Installing 1 2 sudo aptitude install php5-dev php-pear sudo pecl install uploadprogress Step 2: The Debian way of enabling uploadprogress.so You need to create a file in conf.d to enable any PHP extension in Debian.\n1 sudo vim /etc/php5/conf.d/uploadprogress.ini Here\u0026rsquo;s what my uploadprogress.ini looks like:\n1 2 # configuration for PHP uploadprogress module extension=uploadprogress.so Step 3: Restart Apache2 1 sudo /etc/init.d/apache2 restart ","date":"2010-01-09T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/jquery-progress-bar-pecl-c-php-module-debian/JQuery_logo_text.svg","permalink":"https://mythicalprogrammer.github.io/p/jquery-progress-bar-pecl-c-php-module-debian/","title":"Jquery Progress Bar, pecl c, PHP module, Debian"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nProblem: Product\u0026rsquo;s images are not showing\nOne possible cause mentioned in the Ubercart forum is that Clean URLs is not enabled.\nStep 1: Enable mod_rewrite Clean URLs requires mod_rewrite to be enabled\n(Note: mod_rewrite is an Apache 2 module)\nTo check if mod_rewrite is enabled, run the following command:\n1 /usr/sbin/apache2ctl -M Look for:\n1 rewrite_module This is the mod_rewrite module required for Clean URLs.\nStep 2: Enable mod_rewrite if it\u0026rsquo;s not enabled To enable mod_rewrite, run:\n1 sudo /usr/sbin/a2enmod rewrite After entering the command, you should see:\n1 2 Enabling module rewrite. Run \u0026#39;/etc/init.d/apache2 restart\u0026#39; to activate new configuration! To disable mod_rewrite, use:\n1 sudo /usr/sbin/a2dismod rewrite After disabling, you should see:\n1 2 Module rewrite disabled. Run \u0026#39;/etc/init.d/apache2 restart\u0026#39; to activate new configuration! Remember to restart Apache 2 after making changes:\n1 sudo /etc/init.d/apache2 restart Step 3: Check Your Apache 2 Configuration (I\u0026rsquo;m an Apache 2 noob, so bear with me.)\nIn the /etc/apache2/sites-enabled folder, create a config file for your Drupal site.\nExample file: /etc/apache2/sites-enabled/drupal.conf\nBasic Configuration: 1 2 3 4 5 6 7 8 9 10 \u0026lt;VirtualHost *:80\u0026gt; ServerName www.example.com DocumentRoot /var/www/drupal-6.13 \u0026lt;Directory /var/www/drupal-6.13\u0026gt; Options FollowSymLinks AllowOverride None Order allow,deny Allow from all \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; Enable Rewrite Rules Add the following inside the \u0026lt;Directory\u0026gt; section:\n1 2 3 4 5 RewriteEngine on RewriteBase / RewriteCond %{REQUEST_FILENAME} !-f RewriteCond %{REQUEST_FILENAME} !-d RewriteRule ^(.*)$ index.php?q=$1 [L,QSA] Final Configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;VirtualHost *:80\u0026gt; ServerName www.example.com DocumentRoot /var/www/drupal-6.13 \u0026lt;Directory /var/www/drupal-6.13\u0026gt; RewriteEngine on RewriteBase / RewriteCond %{REQUEST_FILENAME} !-f RewriteCond %{REQUEST_FILENAME} !-d RewriteRule ^(.*)$ index.php?q=$1 [L,QSA] Options FollowSymLinks AllowOverride None Order allow,deny Allow from all \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; Restart Apache 2 again:\n1 sudo /etc/init.d/apache2 restart Step 4: Enable Clean URLs in Drupal Go to Administer → Site Configuration → Clean URLs\nYou should see the following path:\n1 home \u0026gt; administer \u0026gt; site configuration Enable Clean URLs.\nTa-da! 🎉 Now the product images should display correctly!\nSystem Information: Debian Lenny with Apache 2\nFor more information about mod_rewrite:\nApache module mod_rewrite\nResources: Clean URLs | drupal.org Example Clean URL configuration of httpd.conf for performance | drupal.org A three-step process for clean URLs in Drupal for Debian Lenny ","date":"2009-10-16T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/ubercart-quest-clean-url-for-drupal/ubercart_huaf6ad0d05eab255de2118121d4f7b124_8882_120x120_fill_box_smart1_3.png","permalink":"https://mythicalprogrammer.github.io/p/ubercart-quest-clean-url-for-drupal/","title":"Ubercart Quest: Clean URL for Drupal"},{"content":"Note: This post was created awhile back on another platform and I migrated to my current one.\nDrupal 6 Performance Issues and Optimization Drupal 6 is incredibly slow right now. Adam and I just installed a lot of modules and enabled them.\nSetup Debian 5 with Apache 2\n1st Assumption: Database Accessing the database could be the reason for the slowdown. Checking the MySQL logs (/var/log) reveals nothing—perhaps I didn’t enable logging. I’ll check on that later.\n2nd Assumption: Modules Let\u0026rsquo;s disable all the modules! This helped just a little. During this process, I also disabled all caching options in Drupal.\nA Surprising Discovery After taking a day-long break, I checked the website again, and it was fast! However, when clicking on the administration URL, it was still very slow. Here\u0026rsquo;s what I found on the Drupal support forum:\n\u0026ldquo;The admin pages in Drupal 6 are slow because they perform a lot of housekeeping and rebuilding (thousands of queries, as you noticed, and these are not just cosmetic). Caching probably won’t help with that.\nIf it is unworkable, disabling the update status module will probably help a bit. There are open issues for reducing the number of queries in future updates, but don’t expect the D6 admin pages to become snappy. They take the hit for some tasks that make the user part of the site more reliable.\nAbout the normal site pages\u0026hellip; the usual optimization methods should apply.\u0026rdquo;\n— cog.rusty, February 21, 2009\nOptimization Steps Alright, let’s optimize the webpage.\nInstalled Tools: Life-of-Request Info extension Devel module (Where is this log file?) 1st Optimization: PHP Optimization with APC I installed the APC package for PHP (read about it here).\nHere’s a tutorial on using APC:\nAPC on Debian Lenny\nPerformance Results: Accessing main Drupal as webmaster:\n1st try: 1.3s 2nd try (browser cache cleared): 0.661s 3rd try: 0.877s As a non-user:\n0.536s Enabling All Modules Main page: 1.114s - 1.124s Content-generated pages: ~0.224s, at most \u0026lt; 0.5s (no images, just text) Yay, it’s faster! 🚀\n","date":"2009-09-20T00:00:00Z","image":"https://mythicalprogrammer.github.io/p/drupal-6-is-slow/Drupal_Logo_Horizontal_Blue.svg","permalink":"https://mythicalprogrammer.github.io/p/drupal-6-is-slow/","title":"Drupal 6 is SLOW"}]